<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hive on JavaChen Blog</title>
    <link>https://blog.javachen.space/tags/hive/</link>
    <description>Recent content in hive on JavaChen Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 30 Apr 2015 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.javachen.space/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>测试Hive集成Sentry</title>
      <link>https://blog.javachen.space/2015/04/30/test-hive-with-sentry/</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/04/30/test-hive-with-sentry/</guid>
      <description>本文在安装和配置Sentry基础之上测试Hive集成Sentry。注意：这里Hive中并没有配置Kerberos认证。 关于配置了Kerber</description>
    </item>
    
    <item>
      <title>Apache Sentry架构介绍</title>
      <link>https://blog.javachen.space/2015/04/29/apache-sentry-architecture/</link>
      <pubDate>Wed, 29 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/04/29/apache-sentry-architecture/</guid>
      <description>介绍 Apache Sentry是Cloudera公司发布的一个Hadoop开源组件，截止目前还是Apache的孵化项目，它提供了细粒度级、基于角色的授权</description>
    </item>
    
    <item>
      <title>配置安全的Hive集群集成Sentry</title>
      <link>https://blog.javachen.space/2014/11/14/config-secured-hive-with-sentry/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/14/config-secured-hive-with-sentry/</guid>
      <description>本文主要记录配置安全的Hive集群集成Sentry的过程。Hive上配置了Kerberos认证，配置的过程请参考： 使用yum安装CDH Had</description>
    </item>
    
    <item>
      <title>配置安全的Impala集群集成Sentry</title>
      <link>https://blog.javachen.space/2014/11/14/config-secured-impala-with-sentry/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/14/config-secured-impala-with-sentry/</guid>
      <description>本文主要记录配置安全的Impala集群集成Sentry的过程。Impala集群上配置了Kerberos认证，并且需要提前配置好Hive与Ke</description>
    </item>
    
    <item>
      <title>Hive配置Kerberos认证</title>
      <link>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-hive/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-hive/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>当前数据仓库建设过程</title>
      <link>https://blog.javachen.space/2014/10/23/hive-warehouse-in-2014/</link>
      <pubDate>Thu, 23 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/10/23/hive-warehouse-in-2014/</guid>
      <description>一个典型的企业数据仓库通常包含数据采集、数据加工和存储、数据展现等几个过程，本篇文章将按照这个顺序记录部门当前建设数据仓库的过程。 1. 数据采集</description>
    </item>
    
    <item>
      <title>采集日志到Hive</title>
      <link>https://blog.javachen.space/2014/07/25/collect-log-to-hive/</link>
      <pubDate>Fri, 25 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/07/25/collect-log-to-hive/</guid>
      <description>我们现在的需求是需要将线上的日志以小时为单位采集并存储到 hive 数据库中，方便以后使用 mapreduce 或者 impala 做数据分析。为了实现这个目标调研了 flume 如何采集数据到 h</description>
    </item>
    
    <item>
      <title>Hive中的排序语法</title>
      <link>https://blog.javachen.space/2014/06/22/sort-in-hive-query/</link>
      <pubDate>Sun, 22 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/22/sort-in-hive-query/</guid>
      <description>ORDER BY hive中的ORDER BY语句和关系数据库中的sql语法相似。他会对查询结果做全局排序，这意味着所有的数据会传送到一个Reduce任务上</description>
    </item>
    
    <item>
      <title>HBase源码分析：HTable put过程</title>
      <link>https://blog.javachen.space/2014/06/13/hbase-code-about-htable-put/</link>
      <pubDate>Fri, 13 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/13/hbase-code-about-htable-put/</guid>
      <description>HBase版本：0.94.15-cdh4.7.0 在 HBase中，大部分的操作都是在RegionServer完成的，Client端想要插入、删</description>
    </item>
    
    <item>
      <title>Hive Over HBase的介绍</title>
      <link>https://blog.javachen.space/2014/06/12/intro-of-hive-over-hbase/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/12/intro-of-hive-over-hbase/</guid>
      <description>Hive Over HBase是基于Hive的HQL查询引擎支持对hbase表提供及时查询的功能，它并不是将hql语句翻译成mapreduce来运行，其响应</description>
    </item>
    
    <item>
      <title>Hive中数据的加载和导出</title>
      <link>https://blog.javachen.space/2014/06/09/hive-data-manipulation-language/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/09/hive-data-manipulation-language/</guid>
      <description>关于 Hive DML 语法，你可以参考 apache 官方文档的说明:Hive Data Manipulation Language。 apache的hive版本现在应该是 0.13.0，而我使用的 hadoop 版本是</description>
    </item>
    
    <item>
      <title>Hive中的FetchTask任务</title>
      <link>https://blog.javachen.space/2014/06/09/fetchtask-in-hive/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/09/fetchtask-in-hive/</guid>
      <description>Hive中有各种各样的Task任务，其中FetchTask算是最简单的一种了。FetchTask不同于MapReduce任务，它不会启动ma</description>
    </item>
    
    <item>
      <title>Hive使用HAProxy配置HA</title>
      <link>https://blog.javachen.space/2014/01/08/hive-ha-by-haproxy/</link>
      <pubDate>Wed, 08 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/01/08/hive-ha-by-haproxy/</guid>
      <description>HAProxy是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，HAProxy是完全免费的、借助HAP</description>
    </item>
    
    <item>
      <title>HiveServer2中使用jdbc客户端用户运行mapreduce</title>
      <link>https://blog.javachen.space/2013/10/17/run-mapreduce-with-client-user-in-hive-server2/</link>
      <pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/10/17/run-mapreduce-with-client-user-in-hive-server2/</guid>
      <description>最近做了个web系统访问hive数据库，类似于官方自带的hwi、安居客的hwi改进版和大众点评的polestar(github地址)系统，但</description>
    </item>
    
    <item>
      <title>使用yum源安装CDH集群</title>
      <link>https://blog.javachen.space/2013/04/06/install-cloudera-cdh-by-yum/</link>
      <pubDate>Sat, 06 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/04/06/install-cloudera-cdh-by-yum/</guid>
      <description>本文主要是记录使用yum安装CDH Hadoop集群的过程，包括HDFS、Yarn、Hive和HBase。目前使用的是CDH6.2.0安装集群</description>
    </item>
    
    <item>
      <title>手动安装Cloudera Hive CDH</title>
      <link>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-hive-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-hive-CDH/</guid>
      <description>本文主要记录手动安装Cloudera Hive集群过程，环境设置及Hadoop安装过程见手动安装Cloudera Hadoop CDH,参考这篇文章，had</description>
    </item>
    
  </channel>
</rss>