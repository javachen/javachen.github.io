<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>parquet on 关注Java、Hadoop、Kubernetes和BI</title>
    <link>https://blog.javachen.space/tags/parquet/</link>
    <description>Recent content in parquet on 关注Java、Hadoop、Kubernetes和BI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 03 Apr 2015 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.javachen.space/tags/parquet/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark SQL中的数据源</title>
      <link>https://blog.javachen.space/2015/04/03/spark-sql-datasource/</link>
      <pubDate>Fri, 03 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/04/03/spark-sql-datasource/</guid>
      <description>Spark 支持通过 DataFrame 来操作大量的数据源，包括外部文件（如 json、avro、parquet、sequencefile 等等）、hive、关系数据库、c</description>
    </item>
    
    <item>
      <title>将Avro数据转换为Parquet格式</title>
      <link>https://blog.javachen.space/2015/03/25/converting-avro-data-to-parquet-format/</link>
      <pubDate>Wed, 25 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/03/25/converting-avro-data-to-parquet-format/</guid>
      <description>本文主要测试将Avro数据转换为Parquet格式的过程并查看 Parquet 文件的 schema 和元数据。 准备 将文本数据转换为 Parquet 格式并读取内容，可以参考 Cloudera 的 MapReduce 例子：</description>
    </item>
    
  </channel>
</rss>