<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hadoop on 关注Java、Hadoop、Kubernetes和BI</title>
    <link>https://blog.javachen.space/tags/hadoop/</link>
    <description>Recent content in hadoop on 关注Java、Hadoop、Kubernetes和BI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 26 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.javachen.space/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Docker搭建hadoop和hive环境</title>
      <link>https://blog.javachen.space/2019/07/26/install-hadoop-and-hive-with-docker/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2019/07/26/install-hadoop-and-hive-with-docker/</guid>
      <description>文将介绍如何在docker上从零开始安装hadoop以及hive环境。本文不会介绍如何安装docker，也不会过多的介绍docker各个命令</description>
    </item>
    
    <item>
      <title>Cloudera Manager安装Haddop集群</title>
      <link>https://blog.javachen.space/2019/03/28/install-hadoop-cluster-with-cm6/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2019/03/28/install-hadoop-cluster-with-cm6/</guid>
      <description>在开始之前，请参考我博客中的关于如何安装cdh集群的文章，这里只做简单说明。因为只是为了测试，所以是在vagrant虚拟机中创建三个虚拟机搭</description>
    </item>
    
    <item>
      <title>Hadoop Streaming 原理</title>
      <link>https://blog.javachen.space/2015/02/12/hadoop-streaming/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/02/12/hadoop-streaming/</guid>
      <description>简介 Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的</description>
    </item>
    
    <item>
      <title>Useful Hadoop Commands</title>
      <link>https://blog.javachen.space/2015/02/10/useful-commands-in-hadoop/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/02/10/useful-commands-in-hadoop/</guid>
      <description>hadoop 解压 gz 文件到文本文件 1 $ hadoop fs -text /hdfs_path/compressed_file.gz | hadoop fs -put - /tmp/uncompressed-file.txt 解压本地文件 gz 文件并上传到 hdfs 1 $ gunzip -c filename.txt.gz | hadoop fs -put - /tmp/filename.txt 使用 awk 处理 csv 文件，参考 Using awk and friends with Hadoop: 1 $ hadoop fs -cat</description>
    </item>
    
    <item>
      <title>安装和部署Presto</title>
      <link>https://blog.javachen.space/2015/01/26/install-and-deploy-presto/</link>
      <pubDate>Mon, 26 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/01/26/install-and-deploy-presto/</guid>
      <description>1. 安装环境 操作系统：CentOs6.5 Hadoop 集群：CDH5.3 JDK 版本：jdk1.8.0_31 为了测试简单，我是将 Presto 的 coordinator 和 worker 都部署在 cdh1 节点上，并且</description>
    </item>
    
    <item>
      <title>CDH 5.2中Impala认证集成LDAP和Kerberos</title>
      <link>https://blog.javachen.space/2015/01/23/new-in-cdh-5-2-impala-authentication-with-ldap-and-kerberos/</link>
      <pubDate>Fri, 23 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/01/23/new-in-cdh-5-2-impala-authentication-with-ldap-and-kerberos/</guid>
      <description>这是一篇翻译的文章，原文为 New in CDH 5.2: Impala Authentication with LDAP and Kerberos。由于翻译水平有限，难免会一些翻译不准确的地方，欢迎指正！ Impala 认证现在可以通过 LDAP 和</description>
    </item>
    
    <item>
      <title>Presto介绍</title>
      <link>https://blog.javachen.space/2015/01/23/presto-overview/</link>
      <pubDate>Fri, 23 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2015/01/23/presto-overview/</guid>
      <description>1. 简介 Presto 是一个运行在集群之上的分布式系统。一个完全的安装报考一个 coordinator 进程和多个 workers 进程。查询通过一个客户端例如 Presto CLI 提交到 coordinator 进程。这个 coordinator 进程解析、</description>
    </item>
    
    <item>
      <title>Hadoop集群部署权限总结</title>
      <link>https://blog.javachen.space/2014/11/25/quikstart-for-config-kerberos-ldap-and-sentry-in-hadoop/</link>
      <pubDate>Tue, 25 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/25/quikstart-for-config-kerberos-ldap-and-sentry-in-hadoop/</guid>
      <description>这是一篇总结的文章，主要介绍 Hadoop 集群快速部署权限的步骤以及一些注意事项。如果你想了解详细的过程，请参考本博客中其他的文章。 1. 开始之前 hadoop 集群一共</description>
    </item>
    
    <item>
      <title>Hadoop配置LDAP集成Kerberos</title>
      <link>https://blog.javachen.space/2014/11/12/config-ldap-with-kerberos-in-cdh-hadoop/</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/12/config-ldap-with-kerberos-in-cdh-hadoop/</guid>
      <description>本文主要记录 cdh hadoop 集群集成 ldap 的过程，这里 ldap 安装的是 OpenLDAP 。LDAP 用来做账号管理，Kerberos作为认证。授权一般来说是由应用来决定的，通过在 LDAP</description>
    </item>
    
    <item>
      <title>Hive配置Kerberos认证</title>
      <link>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-hive/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-hive/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>Impala配置Kerberos认证</title>
      <link>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-impala/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/06/config-kerberos-in-cdh-impala/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>HDFS配置Kerberos认证</title>
      <link>https://blog.javachen.space/2014/11/04/config-kerberos-in-cdh-hdfs/</link>
      <pubDate>Tue, 04 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/11/04/config-kerberos-in-cdh-hdfs/</guid>
      <description>本文主要记录 CDH Hadoop 集群上配置 HDFS 集成 Kerberos 的过程，包括 Kerberos 的安装和 Hadoop 相关配置修改说明。 1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：C</description>
    </item>
    
    <item>
      <title>升级cdh4到cdh5</title>
      <link>https://blog.javachen.space/2014/08/19/upgrading-from-cdh4-to-cdh5/</link>
      <pubDate>Tue, 19 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/08/19/upgrading-from-cdh4-to-cdh5/</guid>
      <description>本文主要记录从CDH4升级到CDH5的过程和遇到的问题，当然本文同样适用于CDH5低版本向最新版本的升级。 1. 不兼容的变化 升级前，需要注意 cdh5 有</description>
    </item>
    
    <item>
      <title>Flume-ng的原理和使用</title>
      <link>https://blog.javachen.space/2014/07/22/flume-ng/</link>
      <pubDate>Tue, 22 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/07/22/flume-ng/</guid>
      <description>1. 介绍 Flume NG是Cloudera提供的一个分布式、可靠、可用的系统，它能够将不同数据源的海量日志数据进行高效收集、聚合、移动，最后存储到一个中</description>
    </item>
    
    <item>
      <title>CDH中配置HDFS HA</title>
      <link>https://blog.javachen.space/2014/07/18/install-hdfs-ha-in-cdh/</link>
      <pubDate>Fri, 18 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/07/18/install-hdfs-ha-in-cdh/</guid>
      <description>最近又安装 hadoop 集群， 故尝试了一下配置 HDFS 的 HA，CDH4支持Quorum-based Storage和shared storage using NFS两种HA方案，而CDH</description>
    </item>
    
    <item>
      <title>不用Cloudera Manager安装Cloudera Search</title>
      <link>https://blog.javachen.space/2014/06/03/install_cloudera_search_without_cm/</link>
      <pubDate>Tue, 03 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/06/03/install_cloudera_search_without_cm/</guid>
      <description>Cloudera Search 用来在 hadoop 基础上建立索引和全文检索，本文主要记录如何安装 CLoudera Search 的过程，其中也包括如何安装和启动 Zookeeper、Solr、MapReduc</description>
    </item>
    
    <item>
      <title>HBase笔记：Region拆分策略</title>
      <link>https://blog.javachen.space/2014/01/16/hbase-region-split-policy/</link>
      <pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2014/01/16/hbase-region-split-policy/</guid>
      <description>Region 概念 Region是表获取和分布的基本元素，由每个列族的一个Store组成。对象层级图如下： 1 2 3 4 5 6 Table (HBase table) Region (Regions for the table) Store (Store per ColumnFamily for each Region for the table)</description>
    </item>
    
    <item>
      <title>远程调试Hadoop各组件</title>
      <link>https://blog.javachen.space/2013/08/01/remote-debug-hadoop/</link>
      <pubDate>Thu, 01 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/08/01/remote-debug-hadoop/</guid>
      <description>远程调试对应用程序开发十分有用。例如，为不能托管开发平台的低端机器开发程序，或在专用的机器上（比如服务不能中断的 Web 服务器）调试程序。其他情况</description>
    </item>
    
    <item>
      <title>安装RHadoop</title>
      <link>https://blog.javachen.space/2013/07/20/install-rhadoop/</link>
      <pubDate>Sat, 20 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/07/20/install-rhadoop/</guid>
      <description>1. R Language Install 安装相关依赖 yum install -y perl* pcre-devel tcl-devel zlib-devel bzip2-devel libX11-devel tk-devel tetex-latex *gfortran* compat-readline5 yum install libRmath-* rpm -Uvh --force --nodeps R-core-2.10.0-2.el5.x86_64.rpm rpm -Uvh R-2.10.0-2.el5.x86_64.rpm R-devel-2.10.0-2.el5.x86_64.rpm 编译安装：R-3.0.1 tar -zxvf R-3.0.1 ./configure make make install #R运行 export HADOOP_CMD=/usr/bin/hadoop 排错 1、错误1 error: --with-readline=yes (default)</description>
    </item>
    
    <item>
      <title>使用yum源安装CDH集群</title>
      <link>https://blog.javachen.space/2013/04/06/install-cloudera-cdh-by-yum/</link>
      <pubDate>Sat, 06 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/04/06/install-cloudera-cdh-by-yum/</guid>
      <description>本文主要是记录使用yum安装CDH Hadoop集群的过程，包括HDFS、Yarn、Hive和HBase。目前使用的是CDH6.2.0安装集群</description>
    </item>
    
    <item>
      <title>手动安装Cloudera Hive CDH</title>
      <link>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-hive-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-hive-CDH/</guid>
      <description>本文主要记录手动安装Cloudera Hive集群过程，环境设置及Hadoop安装过程见手动安装Cloudera Hadoop CDH,参考这篇文章，had</description>
    </item>
    
    <item>
      <title>手动安装Hadoop集群</title>
      <link>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-Hadoop-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://blog.javachen.space/2013/03/24/manual-install-Cloudera-Hadoop-CDH/</guid>
      <description>安装版本 centos版本为6。 hadoop各个组件和jdk版本如下： 1 2 3 4 hadoop-2.0.0-cdh4.6.0 hbase-0.94.15-cdh4.6.0 hive-0.10.0-cdh4.6.0 jdk1.6.0_38 hadoop各组件可以在这里下载。 安装前说明 确定安装目录</description>
    </item>
    
  </channel>
</rss>