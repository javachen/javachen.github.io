<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>spark-shell脚本分析 - JavaChen Blog - Ramblings of a coder</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="JavaChen" /><meta name="description" content="本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解spark中各个进程的参数、JVM参数和内存大小如何设置。" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.58.3 with theme even" />


<link rel="canonical" href="http://localhost:1313/2015/06/26/spark-shell-command/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">
<link rel="stylesheet" href="/css/custom.css">


<meta property="og:title" content="spark-shell脚本分析" />
<meta property="og:description" content="本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解spark中各个进程的参数、JVM参数和内存大小如何设置。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/2015/06/26/spark-shell-command/" />
<meta property="article:published_time" content="2015-06-26T08:00:00+08:00" />
<meta property="article:modified_time" content="2015-06-26T08:00:00+08:00" />
<meta itemprop="name" content="spark-shell脚本分析">
<meta itemprop="description" content="本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解spark中各个进程的参数、JVM参数和内存大小如何设置。">


<meta itemprop="datePublished" content="2015-06-26T08:00:00&#43;08:00" />
<meta itemprop="dateModified" content="2015-06-26T08:00:00&#43;08:00" />
<meta itemprop="wordCount" content="3228">



<meta itemprop="keywords" content="spark," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="spark-shell脚本分析"/>
<meta name="twitter:description" content="本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解spark中各个进程的参数、JVM参数和内存大小如何设置。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">JavaChen Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">JavaChen Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">spark-shell脚本分析</h1>

      <div class="post-meta">
        <span class="post-time"> 2015-06-26 </span>
        <div class="post-category">
            <a href="/categories/spark/"> spark </a>
            </div>
          <span class="more-meta"> 约 3228 字 </span>
          <span class="more-meta"> 预计阅读 7 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#spark-shell">spark-shell</a></li>
<li><a href="#spark-submit">spark-submit</a></li>
<li><a href="#spark-class">spark-class</a></li>
</ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="2015-06-26T08:00:00" title="June 26, 2015">June 26, 2015</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      

<p>本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解spark中各个进程的参数、JVM参数和内存大小如何设置。</p>

<h1 id="spark-shell">spark-shell</h1>

<p>使用yum安装spark之后，你可以直接在终端运行spark-shell命令，或者在spark的home目录/usr/lib下运行bin-shell命令，这样就可以进入到spark命令行交互模式。</p>

<p><strong>spark-shell 脚本是如何运行的呢</strong>？该脚本代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">#
<span class="c1"># Shell script for starting the Spark Shell REPL</span>

<span class="nv">cygwin</span><span class="o">=</span><span class="nb">false</span>
<span class="k">case</span> <span class="s2">&#34;`uname`&#34;</span> in
  CYGWIN*<span class="o">)</span> <span class="nv">cygwin</span><span class="o">=</span>true<span class="p">;;</span>
<span class="k">esac</span>

<span class="c1"># Enter posix mode for bash</span>
<span class="nb">set</span> -o posix

<span class="c1">## Global script variables</span>
<span class="nv">FWDIR</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span><span class="nb">cd</span> <span class="s2">&#34;`dirname &#34;</span><span class="nv">$0</span><span class="s2">&#34;`&#34;</span>/..<span class="p">;</span> <span class="nb">pwd</span><span class="k">)</span><span class="s2">&#34;</span>

<span class="k">function</span> usage<span class="o">()</span> <span class="o">{</span>
  <span class="nb">echo</span> <span class="s2">&#34;Usage: ./bin-shell [options]&#34;</span>
  <span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin-submit --help <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> grep -v Usage <span class="m">1</span>&gt;<span class="p">&amp;</span><span class="m">2</span>
  <span class="nb">exit</span> <span class="m">0</span>
<span class="o">}</span>

<span class="k">if</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span> <span class="o">=</span> *--help <span class="o">]]</span> <span class="o">||</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span> <span class="o">=</span> *-h <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
  usage
<span class="k">fi</span>

<span class="nb">source</span> <span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin/utils.sh
<span class="nv">SUBMIT_USAGE_FUNCTION</span><span class="o">=</span>usage
gatherSparkSubmitOpts <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span>

<span class="c1"># SPARK-4161: scala does not assume use of the java classpath,</span>
<span class="c1"># so we need to add the &#34;-Dscala.usejavacp=true&#34; flag mnually. We</span>
<span class="c1"># do this specifically for the Spark shell because the scala REPL</span>
<span class="c1"># has its own class loader, and any additional classpath specified</span>
<span class="c1"># through spark.driver.extraClassPath is not automatically propagated.</span>
<span class="nv">SPARK_SUBMIT_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_OPTS</span><span class="s2"> -Dscala.usejavacp=true&#34;</span>

<span class="k">function</span> main<span class="o">()</span> <span class="o">{</span>
  <span class="k">if</span> <span class="nv">$cygwin</span><span class="p">;</span> <span class="k">then</span>
    <span class="c1"># Workaround for issue involving JLine and Cygwin</span>
    <span class="c1"># (see http://sourceforge.net/p/jline/bugs/40/).</span>
    <span class="c1"># If you&#39;re using the Mintty terminal emulator in Cygwin, may need to set the</span>
    <span class="c1"># &#34;Backspace sends ^H&#34; setting in &#34;Keys&#34; section of the Mintty options</span>
    <span class="c1"># (see https://github.com/sbt/sbt/issues/562).</span>
    stty -icanon min <span class="m">1</span> -echo &gt; /dev/null <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_OPTS</span><span class="s2"> -Djline.terminal=unix&#34;</span>
    <span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin-submit --class org.apache.spark.repl.Main <span class="s2">&#34;</span><span class="si">${</span><span class="nv">SUBMISSION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span> spark-shell <span class="s2">&#34;</span><span class="si">${</span><span class="nv">APPLICATION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span>
    stty icanon <span class="nb">echo</span> &gt; /dev/null <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
  <span class="k">else</span>
    <span class="nb">export</span> SPARK_SUBMIT_OPTS
    <span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin-submit --class org.apache.spark.repl.Main <span class="s2">&#34;</span><span class="si">${</span><span class="nv">SUBMISSION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span> spark-shell <span class="s2">&#34;</span><span class="si">${</span><span class="nv">APPLICATION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span>
  <span class="k">fi</span>
<span class="o">}</span>

<span class="c1"># Copy restore-TTY-on-exit functions from Scala script so spark-shell exits properly even in</span>
<span class="c1"># binary distribution of Spark where Scala is not installed</span>
<span class="nv">exit_status</span><span class="o">=</span><span class="m">127</span>
<span class="nv">saved_stty</span><span class="o">=</span><span class="s2">&#34;&#34;</span>

<span class="c1"># restore stty settings (echo in particular)</span>
<span class="k">function</span> restoreSttySettings<span class="o">()</span> <span class="o">{</span>
  stty <span class="nv">$saved_stty</span>
  <span class="nv">saved_stty</span><span class="o">=</span><span class="s2">&#34;&#34;</span>
<span class="o">}</span>

<span class="k">function</span> onExit<span class="o">()</span> <span class="o">{</span>
  <span class="k">if</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$saved_stty</span><span class="s2">&#34;</span> !<span class="o">=</span> <span class="s2">&#34;&#34;</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
    restoreSttySettings
  <span class="k">fi</span>
  <span class="nb">exit</span> <span class="nv">$exit_status</span>
<span class="o">}</span>

<span class="c1"># to reenable echo if we are interrupted before completing.</span>
<span class="nb">trap</span> onExit INT

<span class="c1"># save terminal settings</span>
<span class="nv">saved_stty</span><span class="o">=</span><span class="k">$(</span>stty -g <span class="m">2</span>&gt;/dev/null<span class="k">)</span>
<span class="c1"># clear on error so we don&#39;t later try to restore them</span>
<span class="k">if</span> <span class="o">[[</span> ! <span class="nv">$?</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
  <span class="nv">saved_stty</span><span class="o">=</span><span class="s2">&#34;&#34;</span>
<span class="k">fi</span>

main <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span>

<span class="c1"># record the exit status lest it be overwritten:</span>
<span class="c1"># then reenable echo and propagate the code.</span>
<span class="nv">exit_status</span><span class="o">=</span><span class="nv">$?</span>
onExit</code></pre></td></tr></table>
</div>
</div>
<p>从上往下一步步分析，首先是判断是否为cygwin，这里用到了bash中的<code>case</code>语法：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">cygwin</span><span class="o">=</span><span class="nb">false</span>
<span class="k">case</span> <span class="s2">&#34;`uname`&#34;</span> in
  CYGWIN*<span class="o">)</span> <span class="nv">cygwin</span><span class="o">=</span>true<span class="p">;;</span>
<span class="k">esac</span></code></pre></td></tr></table>
</div>
</div>
<blockquote>
<p>在linux系统中，<code>uname</code>命令的运行结果为linux，其值不等于<code>CYGWIN*</code>，故cygwin=false。</p>
</blockquote>

<p>开启bash的posix模式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">set</span> -o posix</code></pre></td></tr></table>
</div>
</div>
<p>获取上级目录绝对路径，这里使用到了<code>dirname</code>命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">FWDIR</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span><span class="nb">cd</span> <span class="s2">&#34;`dirname &#34;</span><span class="nv">$0</span><span class="s2">&#34;`&#34;</span>/..<span class="p">;</span> <span class="nb">pwd</span><span class="k">)</span><span class="s2">&#34;</span></code></pre></td></tr></table>
</div>
</div>
<blockquote>
<p>提示：bash 中，$0 是获取脚本名称</p>
</blockquote>

<p>判断输入参数中是否有<code>--help</code>或者<code>-h</code>，如果有，则打印使用说明，实际上运行的是<code>/bin-submit --help</code>命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="k">function</span> usage<span class="o">()</span> <span class="o">{</span>
  <span class="nb">echo</span> <span class="s2">&#34;Usage: ./bin-shell [options]&#34;</span>
  <span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin-submit --help <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> grep -v Usage <span class="m">1</span>&gt;<span class="p">&amp;</span><span class="m">2</span>
  <span class="nb">exit</span> <span class="m">0</span>
<span class="o">}</span>

<span class="k">if</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span> <span class="o">=</span> *--help <span class="o">]]</span> <span class="o">||</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span> <span class="o">=</span> *-h <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
  usage
<span class="k">fi</span></code></pre></td></tr></table>
</div>
</div>
<blockquote>
<p>提示：</p>

<ul>
<li>2&gt;&amp;1 的意思是将标准错误也输出到标准输出当中；1&gt;&amp;2是将标准输出输出到标准错误当中</li>
<li>bash 中，$@ 是获取脚本所有的输入参数</li>
</ul>
</blockquote>

<p>再往后面是定义了一个main方法，并将spark-shell的输入参数传给该方法运行，main方法中判断是否是cygwin模式，如果不是，则运行</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">SPARK_SUBMIT_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_OPTS</span><span class="s2"> -Dscala.usejavacp=true&#34;</span>


<span class="nb">export</span> SPARK_SUBMIT_OPTS
<span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">&#34;</span>/bin-submit --class org.apache.spark.repl.Main <span class="s2">&#34;</span><span class="si">${</span><span class="nv">SUBMISSION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span> spark-shell <span class="s2">&#34;</span><span class="si">${</span><span class="nv">APPLICATION_OPTS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span></code></pre></td></tr></table>
</div>
</div>
<blockquote>
<p>提示：&rdquo;${SUBMISSION_OPTS[@]}&rdquo; 这是什么意思？</p>
</blockquote>

<p>从上面可以看到，其实最后调用的是spark-submit命令，并指定<code>--class</code>参数为<code>org.apache.spark.repl.Main</code>类，后面接的是spark-submit的提交参数，再后面是spark-shell，最后是传递应用的参数。</p>

<p>最后，是获取main方法运行结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">exit_status</span><span class="o">=</span><span class="nv">$?</span>
onExit</code></pre></td></tr></table>
</div>
</div>
<blockquote>
<p>提示： bash 中，<code>$?</code>是获取上个命令运行结束返回的状态码</p>
</blockquote>

<p>如果以调试模式运行spark-shell，在不加参数的情况下，输出内容为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></pre></td>
<td class="lntd">
<pre class="chroma">+ cygwin=false
+ case &#34;`uname`&#34; in
++ uname
+ set -o posix
+++ dirname /usr/lib/bin-shell
++ cd /usr/lib/bin/..
++ pwd
+ FWDIR=/usr/lib
+ [[ &#39;&#39; = *--help ]]
+ [[ &#39;&#39; = *-h ]]
+ source /usr/lib/bin/utils.sh
+ SUBMIT_USAGE_FUNCTION=usage
+ gatherSparkSubmitOpts
+ &#39;[&#39; -z usage &#39;]&#39;
+ SUBMISSION_OPTS=()
+ APPLICATION_OPTS=()
+ (( 0 ))
+ export SUBMISSION_OPTS
+ export APPLICATION_OPTS
+ SPARK_SUBMIT_OPTS=&#39; -Dscala.usejavacp=true&#39;
+ exit_status=127
+ saved_stty=
+ trap onExit INT
++ stty -g
+ saved_stty=500:5:bf:8a3b:3:1c:7f:15:4:0:1:0:11:13:1a:0:12:f:17:16:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0
+ [[ ! -n 0 ]]
+ main
+ false
+ export SPARK_SUBMIT_OPTS
+ /usr/lib/bin-submit --class org.apache.spark.repl.Main spark-shell</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>提示：通过运行<code>set -x</code>可以开启bash调试代码的特性。</p>
</blockquote>

<p>接下来就涉及到spark-submit命令的逻辑了。</p>

<h1 id="spark-submit">spark-submit</h1>

<p>完整的spark-submit脚本内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># NOTE: Any changes in this file must be reflected in SparkSubmitDriverBootstrapper.scala!</span>

<span class="nb">export</span> <span class="nv">SPARK_HOME</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span><span class="nb">cd</span> <span class="s2">&#34;`dirname &#34;</span><span class="nv">$0</span><span class="s2">&#34;`&#34;</span>/..<span class="p">;</span> <span class="nb">pwd</span><span class="k">)</span><span class="s2">&#34;</span>
<span class="nv">ORIG_ARGS</span><span class="o">=(</span><span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span><span class="o">)</span>

<span class="c1"># Set COLUMNS for progress bar</span>
<span class="nb">export</span> <span class="nv">COLUMNS</span><span class="o">=</span><span class="sb">`</span>tput cols<span class="sb">`</span>

<span class="k">while</span> <span class="o">((</span><span class="nv">$#</span><span class="o">))</span><span class="p">;</span> <span class="k">do</span>
  <span class="k">if</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--deploy-mode&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nv">SPARK_SUBMIT_DEPLOY_MODE</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--properties-file&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nv">SPARK_SUBMIT_PROPERTIES_FILE</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--driver-memory&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_DRIVER_MEMORY</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--driver-library-path&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--driver-class-path&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_CLASSPATH</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--driver-java-options&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_OPTS</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">elif</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;--master&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">MASTER</span><span class="o">=</span><span class="nv">$2</span>
  <span class="k">fi</span>
  <span class="nb">shift</span>
<span class="k">done</span>

<span class="k">if</span> <span class="o">[</span> -z <span class="s2">&#34;</span><span class="nv">$SPARK_CONF_DIR</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
  <span class="nb">export</span> <span class="nv">SPARK_CONF_DIR</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_HOME</span><span class="s2">/conf&#34;</span>
<span class="k">fi</span>
<span class="nv">DEFAULT_PROPERTIES_FILE</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_CONF_DIR</span><span class="s2">-defaults.conf&#34;</span>
<span class="k">if</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$MASTER</span><span class="s2">&#34;</span> <span class="o">==</span> <span class="s2">&#34;yarn-cluster&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
  <span class="nv">SPARK_SUBMIT_DEPLOY_MODE</span><span class="o">=</span>cluster
<span class="k">fi</span>
<span class="nb">export</span> <span class="nv">SPARK_SUBMIT_DEPLOY_MODE</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_SUBMIT_DEPLOY_MODE</span><span class="k">:-</span><span class="s2">&#34;client&#34;</span><span class="si">}</span>
<span class="nb">export</span> <span class="nv">SPARK_SUBMIT_PROPERTIES_FILE</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_SUBMIT_PROPERTIES_FILE</span><span class="k">:-</span><span class="s2">&#34;</span><span class="nv">$DEFAULT_PROPERTIES_FILE</span><span class="s2">&#34;</span><span class="si">}</span>

<span class="c1"># For client mode, the driver will be launched in the same JVM that launches</span>
<span class="c1"># SparkSubmit, so we may need to read the properties file for any extra class</span>
<span class="c1"># paths, library paths, java options and memory early on. Otherwise, it will</span>
<span class="c1"># be too late by the time the driver JVM has started.</span>

<span class="k">if</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_DEPLOY_MODE</span><span class="s2">&#34;</span> <span class="o">==</span> <span class="s2">&#34;client&#34;</span> <span class="o">&amp;&amp;</span> -f <span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_PROPERTIES_FILE</span><span class="s2">&#34;</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
  <span class="c1"># Parse the properties file only if the special configs exist</span>
  <span class="nv">contains_special_configs</span><span class="o">=</span><span class="k">$(</span>
    grep -e <span class="s2">&#34;spark.driver.extra*\|spark.driver.memory&#34;</span> <span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_PROPERTIES_FILE</span><span class="s2">&#34;</span> <span class="p">|</span> <span class="se">\
</span><span class="se"></span>    grep -v <span class="s2">&#34;^[[:space:]]*#&#34;</span>
  <span class="k">)</span>
  <span class="k">if</span> <span class="o">[</span> -n <span class="s2">&#34;</span><span class="nv">$contains_special_configs</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">export</span> <span class="nv">SPARK_SUBMIT_BOOTSTRAP_DRIVER</span><span class="o">=</span><span class="m">1</span>
  <span class="k">fi</span>
<span class="k">fi</span>

<span class="nb">exec</span> <span class="s2">&#34;</span><span class="nv">$SPARK_HOME</span><span class="s2">&#34;</span>/bin-class org.apache.spark.deploy.SparkSubmit <span class="s2">&#34;</span><span class="si">${</span><span class="nv">ORIG_ARGS</span><span class="p">[@]</span><span class="si">}</span><span class="s2">&#34;</span></code></pre></td></tr></table>
</div>
</div>
<p>首先是设置<code>SPARK_HOME</code>，并保留原始输入参数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">SPARK_HOME</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span><span class="nb">cd</span> <span class="s2">&#34;`dirname &#34;</span><span class="nv">$0</span><span class="s2">&#34;`&#34;</span>/..<span class="p">;</span> <span class="nb">pwd</span><span class="k">)</span><span class="s2">&#34;</span>
<span class="nv">ORIG_ARGS</span><span class="o">=(</span><span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span><span class="o">)</span></code></pre></td></tr></table>
</div>
</div>
<p>接下来，使用while语句配合<code>shift</code>命令，依次判断输入参数。</p>

<blockquote>
<p>说明：shift是将输入参数位置向左移位</p>
</blockquote>

<p>设置<code>SPARK_CONF_DIR</code>变量，并判断spark-submit部署模式。</p>

<p>如果<code>$SPARK_CONF_DIR-defaults.conf</code>文件存在，则检查是否设置<code>spark.driver.extra</code>开头的和<code>spark.driver.memory</code>变量，如果设置了，则<code>SPARK_SUBMIT_BOOTSTRAP_DRIVER</code>设为1。</p>

<p>最后，执行的是spark-class命令，输入参数为<code>org.apache.spark.deploy.SparkSubmit</code>类名和原始参数。</p>

<h1 id="spark-class">spark-class</h1>

<p>该脚本首先还是判断是否是cygwin，并设置SPARK_HOME和SPARK_CONF_DIR变量。</p>

<p>运行bin/load-spark-env.sh，加载spark环境变量。</p>

<p>spark-class至少需要传递一个参数，如果没有，则会打印脚本使用说明<code>Usage: spark-class &lt;class&gt; [&lt;args&gt;]</code>。</p>

<p>如果设置了<code>SPARK_MEM</code>变量，则提示<code>SPARK_MEM</code>变量过时，应该使用<code>spark.executor.memory</code>或者<code>spark.driver.memory</code>变量。</p>

<p>设置默认内存<code>DEFAULT_MEM</code>为512M，如果<code>SPARK_MEM</code>变量存在，则使用<code>SPARK_MEM</code>的值。</p>

<p>使用case语句判断spark-class传入的第一个参数的值：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">SPARK_DAEMON_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_DAEMON_JAVA_OPTS</span><span class="s2"> -Dspark.akka.logLifecycleEvents=true&#34;</span>

<span class="c1"># Add java opts and memory settings for master, worker, history server, executors, and repl.</span>
<span class="k">case</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> in
  <span class="c1"># Master, Worker, and HistoryServer use SPARK_DAEMON_JAVA_OPTS (and specific opts) + SPARK_DAEMON_MEMORY.</span>
  <span class="s1">&#39;org.apache.spark.deploy.master.Master&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_DAEMON_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_MASTER_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_DAEMON_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="p">;;</span>
  <span class="s1">&#39;org.apache.spark.deploy.worker.Worker&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_DAEMON_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_WORKER_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_DAEMON_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="p">;;</span>
  <span class="s1">&#39;org.apache.spark.deploy.history.HistoryServer&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_DAEMON_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_HISTORY_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_DAEMON_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="p">;;</span>

  <span class="c1"># Executors use SPARK_JAVA_OPTS + SPARK_EXECUTOR_MEMORY.</span>
  <span class="s1">&#39;org.apache.spark.executor.CoarseGrainedExecutorBackend&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_EXECUTOR_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_EXECUTOR_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="p">;;</span>
  <span class="s1">&#39;org.apache.spark.executor.MesosExecutorBackend&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_EXECUTOR_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_EXECUTOR_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">/python:</span><span class="nv">$PYTHONPATH</span><span class="s2">&#34;</span>
    <span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$FWDIR</span><span class="s2">/python/lib/py4j-0.8.2.1-src.zip:</span><span class="nv">$PYTHONPATH</span><span class="s2">&#34;</span>
    <span class="p">;;</span>

  <span class="c1"># Spark submit uses SPARK_JAVA_OPTS + SPARK_SUBMIT_OPTS +</span>
  <span class="c1"># SPARK_DRIVER_MEMORY + SPARK_SUBMIT_DRIVER_MEMORY.</span>
  <span class="s1">&#39;org.apache.spark.deploy.SparkSubmit&#39;</span><span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_JAVA_OPTS</span><span class="s2"> </span><span class="nv">$SPARK_SUBMIT_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_DRIVER_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="k">if</span> <span class="o">[</span> -n <span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_LIBRARY_PATH</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
      <span class="k">if</span> <span class="o">[[</span> <span class="nv">$OSTYPE</span> <span class="o">==</span> darwin* <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
       <span class="nb">export</span> <span class="nv">DYLD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_LIBRARY_PATH</span><span class="s2">:</span><span class="nv">$DYLD_LIBRARY_PATH</span><span class="s2">&#34;</span>
      <span class="k">else</span>
       <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_LIBRARY_PATH</span><span class="s2">:</span><span class="nv">$LD_LIBRARY_PATH</span><span class="s2">&#34;</span>
      <span class="k">fi</span>
    <span class="k">fi</span>
    <span class="k">if</span> <span class="o">[</span> -n <span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_DRIVER_MEMORY</span><span class="s2">&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
      <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_SUBMIT_DRIVER_MEMORY</span><span class="s2">&#34;</span>
    <span class="k">fi</span>
    <span class="p">;;</span>

  *<span class="o">)</span>
    <span class="nv">OUR_JAVA_OPTS</span><span class="o">=</span><span class="s2">&#34;</span><span class="nv">$SPARK_JAVA_OPTS</span><span class="s2">&#34;</span>
    <span class="nv">OUR_JAVA_MEM</span><span class="o">=</span><span class="si">${</span><span class="nv">SPARK_DRIVER_MEMORY</span><span class="k">:-</span><span class="nv">$DEFAULT_MEM</span><span class="si">}</span>
    <span class="p">;;</span>
<span class="k">esac</span></code></pre></td></tr></table>
</div>
</div>
<p>可能存在以下几种情况：</p>

<ul>
<li><code>org.apache.spark.deploy.master.Master</code></li>
<li><code>org.apache.spark.deploy.worker.Worker</code></li>
<li><code>org.apache.spark.deploy.history.HistoryServer</code></li>
<li><code>org.apache.spark.executor.CoarseGrainedExecutorBackend</code></li>
<li><code>org.apache.spark.executor.MesosExecutorBackend</code></li>
<li><code>org.apache.spark.deploy.SparkSubmit</code></li>
</ul>

<p>并分别设置每种情况下的Java运行参数和使用内存大小，以表格形式表示如下：</p>

<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">OUR_JAVA_OPTS</th>
<th align="left">OUR_JAVA_MEM</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Master</td>
<td align="left">$SPARK_DAEMON_JAVA_OPTS $SPARK_MASTER_OPTS</td>
<td align="left">${SPARK_DAEMON_MEMORY:-$DEFAULT_MEM}</td>
</tr>

<tr>
<td align="left">Worker</td>
<td align="left">$SPARK_DAEMON_JAVA_OPTS $SPARK_WORKER_OPTS</td>
<td align="left">${SPARK_DAEMON_MEMORY:-$DEFAULT_MEM}</td>
</tr>

<tr>
<td align="left">HistoryServer</td>
<td align="left">$SPARK_DAEMON_JAVA_OPTS $SPARK_HISTORY_OPTS</td>
<td align="left">${SPARK_DAEMON_MEMORY:-$DEFAULT_MEM}</td>
</tr>

<tr>
<td align="left">CoarseGrainedExecutorBackend</td>
<td align="left">$SPARK_JAVA_OPTS $SPARK_EXECUTOR_OPTS</td>
<td align="left">${SPARK_EXECUTOR_MEMORY:-$DEFAULT_MEM}</td>
</tr>

<tr>
<td align="left">MesosExecutorBackend</td>
<td align="left">$SPARK_JAVA_OPTS $SPARK_EXECUTOR_OPTS</td>
<td align="left">${SPARK_EXECUTOR_MEMORY:-$DEFAULT_MEM}</td>
</tr>

<tr>
<td align="left">SparkSubmit</td>
<td align="left">$SPARK_JAVA_OPTS $SPARK_SUBMIT_OPTS</td>
<td align="left">${SPARK_DRIVER_MEMORY:-$DEFAULT_MEM}</td>
</tr>
</tbody>
</table>

<p>通过上表就可以知道每一个spark中每个进程如何设置JVM参数和内存大小。</p>

<p>接下来是查找JAVA_HOME并检查Java版本。</p>

<p>设置SPARK_TOOLS_JAR变量。</p>

<p>运行bin/compute-classpath.sh计算classpath。</p>

<p>判断<code>SPARK_SUBMIT_BOOTSTRAP_DRIVER</code>变量值，如果该值为1，则运行<code>org.apache.spark.deploy.SparkSubmitDriverBootstrapper</code>类，以替换原来的<code>org.apache.spark.deploy.SparkSubmit</code>的类，执行的脚本为<code>exec &quot;$RUNNER&quot; org.apache.spark.deploy.SparkSubmitDriverBootstrapper &quot;$@&quot;</code>；否则，运行java命令<code>exec &quot;$RUNNER&quot; -cp &quot;$CLASSPATH&quot; $JAVA_OPTS &quot;$@&quot;</code>。</p>

<p>从最后运行的脚本可以看到，spark-class脚本的作用主要是查找java命令、计算环境变量、设置<code>JAVA_OPTS</code>等，至于运行的是哪个java类的main方法，取决于<code>SPARK_SUBMIT_BOOTSTRAP_DRIVER</code>变量的值。</p>

<p>接下来，就是要分析<code>org.apache.spark.deploy.SparkSubmitDriverBootstrapper</code>和<code>org.apache.spark.deploy.SparkSubmit</code>类的运行逻辑以及两者之间的区别，这部分内容见下篇文章。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">JavaChen</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2015-06-26
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/wechatpay.jpg">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/alipay.jpg">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/spark/">spark</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/2015/06/29/advanced-bash-script-programming/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">高级Bash脚本编程入门</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/2015/06/19/scala-object/">
            <span class="next-text nav-default">Scala中的对象</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="javachen/javachen-blog-theme"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:junecloud@163.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-facebook" title="facebook"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-google" title="google"></a>
      <a href="http://github.com/javacehn" class="iconfont icon-github" title="github"></a>
      <a href="http://weibo.com/chenzhijun" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" class="iconfont icon-instagram" title="instagram"></a>
      <a href="http://localhost:1313" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2009 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">JavaChen</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "en".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
