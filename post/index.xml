<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 六月陈书</title>
    <link>https://junetalk.github.io/post/</link>
    <description>Recent content in Posts on 六月陈书</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 26 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://junetalk.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Greenplum数据库备份和恢复</title>
      <link>https://junetalk.github.io/2020/09/26/greenplum-backup-and-restore/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/09/26/greenplum-backup-and-restore/</guid>
      <description>概述 Greenplum数据库支持并行和非并行的方法来备份和恢复数据库。 并行操作的规模不受系统中Segment数量的影响，因为每台Segmen</description>
    </item>
    
    <item>
      <title>使用K3d和Vagrant搭建Kubernetes集群</title>
      <link>https://junetalk.github.io/2020/09/25/install-a-local-cluster-using-k3d-and-vagrant/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/09/25/install-a-local-cluster-using-k3d-and-vagrant/</guid>
      <description>前置条件 VirtualBox Vagrant 使用Vagrant创建虚Centos拟机 创建目录 k3d-cluster： 1 2 3 mkdir k3d-cluster cd k3d-cluster mkdir ./shared 创建Vagrantfile： 1 2 3 4 5</description>
    </item>
    
    <item>
      <title>Pivotal Greenplum-Spark Connector</title>
      <link>https://junetalk.github.io/2020/09/24/greenplum-spark-connector-usage/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/09/24/greenplum-spark-connector-usage/</guid>
      <description>1、介绍 Pivotal Greenplum-Spark Connector 支持在 Greenplum 数据库和 Spark 集群之间高速并行传输数据，它使用： Spark’s Scala API 编程接口访问（包括 spark-shell） Greenplum-Spark Connector 支持： 交互</description>
    </item>
    
    <item>
      <title>Greenplum Database Tutorials</title>
      <link>https://junetalk.github.io/2020/09/23/gpdb-tutorials/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/09/23/gpdb-tutorials/</guid>
      <description>介绍 Greenplum官方有一个 Greenplum Database Tutorials ，里面是使用的虚拟机，本文使用 docker 容器部署一个 Greenplum 实例进行测试。 如果你不想使用docker部署，可以参考我</description>
    </item>
    
    <item>
      <title>TLS on K3s with traefik, cert manger and letsencrypt</title>
      <link>https://junetalk.github.io/2020/03/20/k3s-cert-manager-letsencrypt/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/03/20/k3s-cert-manager-letsencrypt/</guid>
      <description>原文：https://www.thebookofjoel.com/k3s-cert-manager-letsencrypt ，本文只是我的测试</description>
    </item>
    
    <item>
      <title>使用K3d安装K3s</title>
      <link>https://junetalk.github.io/2020/03/20/install-k3s-with-k3d/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/03/20/install-k3s-with-k3d/</guid>
      <description>安装K3d 脚本安装： 1 2 wget -q -O - https://raw.githubusercontent.com/rancher/k3d/master/install.sh | bash curl -s https://raw.githubusercontent.com/rancher/k3d/master/install.sh | bash homebrew安装： 1 brew install k3d 设置环境变量： 1 export KUBECONFIG=&amp;#34;$(k3d get-kubeconfig --name=&amp;#39;k3s-default&amp;#39;)&amp;#34; 本地安装kubectl: 1 2 3 4 5 6 7</description>
    </item>
    
    <item>
      <title>使用K3sup安装K3S</title>
      <link>https://junetalk.github.io/2020/03/19/install-k3s-with-k3sup/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/03/19/install-k3s-with-k3sup/</guid>
      <description>k3sup是一个支持在PC、虚拟机、ARM设备上安装k3s的工具，官方网站：https://k3sup.dev/ 配置SSH k3sup是基于s</description>
    </item>
    
    <item>
      <title>安装K3S</title>
      <link>https://junetalk.github.io/2020/03/18/install-k3s/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/03/18/install-k3s/</guid>
      <description>本文在我购买的虚拟机主机上安装k3s，虚拟主机有公网IP并且做了DNS域名解析。 安装Docker 1 2 3 curl -fsSL get.docker.com | sh usermod -aG docker `whoami` systemctl enable docker &amp;amp;&amp;amp; systemctl start docker 离线安</description>
    </item>
    
    <item>
      <title>vue-element-admin框架修改记录</title>
      <link>https://junetalk.github.io/2020/03/04/record-of-updating-vue-element-admin/</link>
      <pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/03/04/record-of-updating-vue-element-admin/</guid>
      <description>安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 克隆项目 git clone https://github.com/PanJiaChen/vue-element-admin.git # 进入项目目录 cd vue-element-admin # 安装依赖 npm install # 建议不要用 cnpm 安装 会有各种诡异的bug 可以通过如下操作解决 npm</description>
    </item>
    
    <item>
      <title>Devops阅读清单</title>
      <link>https://junetalk.github.io/2020/01/13/devops-reading-list/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2020/01/13/devops-reading-list/</guid>
      <description>DevOps 管理规范 https://www.kancloud.cn/huyipow/devops/971137 Docker — 从入门到实践：https://www.cntofu.com/book/139/index.html Kubernetes中文指</description>
    </item>
    
    <item>
      <title>Traefik使用</title>
      <link>https://junetalk.github.io/2019/12/24/traefik/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/24/traefik/</guid>
      <description>traefik 是一个开源的反向代理和负载均衡工具，现在官方介绍中将其定位为云原生的边缘路由器，且用了一堆修饰词：简单、自动、高速、全面、开源、产品级、内</description>
    </item>
    
    <item>
      <title>安装Prometheus、Grafana、Alertmanager</title>
      <link>https://junetalk.github.io/2019/12/18/install-prometheus-and-grafana-and-alertmanager/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/18/install-prometheus-and-grafana-and-alertmanager/</guid>
      <description>安装Prometheus 1、下载最新版本：https://prometheus.io/download/ 1 2 3 4 5 6 7 wget https://github.com/prometheus/prometheus/releases/download/v2.14.0/prometheus-2.14.0.linux-amd64.tar.gz tar zxvf prometheus-2.14.0.linux-amd64.tar.gz mv prometheus-2.14.0.linux-amd64 /usr/local/prometheus cd /usr/local/prometheus/ &amp;amp;&amp;amp;</description>
    </item>
    
    <item>
      <title>Greenplum常用命令</title>
      <link>https://junetalk.github.io/2019/12/17/often-used-greeplum-commands/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/17/often-used-greeplum-commands/</guid>
      <description>查看数据库状态 1、查看segment 列出当前状态为down的Segment： 1 SELECT * FROM gp_segment_configuration WHERE status &amp;lt;&amp;gt; &amp;#39;u&amp;#39;; 检查当前处于改变跟踪模式的Segment。 1 SELECT</description>
    </item>
    
    <item>
      <title>安装Greenplum Command Center Console</title>
      <link>https://junetalk.github.io/2019/12/16/install-pivotal-greenplum-command-center/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/16/install-pivotal-greenplum-command-center/</guid>
      <description>安装greenplum-cc-web 参考 安装Greenplum数据库集群 先安装好集群，再安装 greenplum-cc-web。 1、下载安装文</description>
    </item>
    
    <item>
      <title>Drone阅读清单</title>
      <link>https://junetalk.github.io/2019/12/12/drone-reading-list/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/12/drone-reading-list/</guid>
      <description>Drone实践 Docker 容器环境下的持续集成最佳实践：构建基于 Drone + GitFlow + K8s 的云原生语义化 CI 工作流 容器环境持续集成优化，Drone CI 提速 500% 在Kubern</description>
    </item>
    
    <item>
      <title>使用Helm安装Drone集成Gitlab</title>
      <link>https://junetalk.github.io/2019/12/11/install-drone-with-gitlab-using-helm/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/11/install-drone-with-gitlab-using-helm/</guid>
      <description>Drone 是用 Go 语言编写的基于 Docker 构建的开源轻量级 CI/CD 工具，可以和 Gitlab 集成使用。本文主要记录安装 Drone 的过程，并集成 Gitlab。 创建证书 参考 使用Cert Ma</description>
    </item>
    
    <item>
      <title>Cert Manager使用ACME-DNS生成证书</title>
      <link>https://junetalk.github.io/2019/12/06/create-certificate-with-cert-manager-using-acme-dns/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/12/06/create-certificate-with-cert-manager-using-acme-dns/</guid>
      <description>之前使用cert-manager-webhook-dnspod来生成DNSPOD的泛域名的证书，但是遇到 一个问题 导致证书生成失败，所以，需要</description>
    </item>
    
    <item>
      <title>Ceph块设备测试</title>
      <link>https://junetalk.github.io/2019/11/30/ceph-rbd-test/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/30/ceph-rbd-test/</guid>
      <description>在搭建了一个Ceph多节点的集群之后，你可以在客户端上连接集群使用Ceph存储上的设备，比如块设备。 配置客户端 1、在管理节点上，通过 ceph-deploy 把 Ceph 安</description>
    </item>
    
    <item>
      <title>Kubernetes常用命令</title>
      <link>https://junetalk.github.io/2019/11/29/some-commads-of-kubernetes/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/29/some-commads-of-kubernetes/</guid>
      <description>查找K8S中高磁盘占用 在节点上执行： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ sudo du -h --max-depth 1 /var/lib/docker/ 187M /var/lib/docker/containers 0 /var/lib/docker/plugins 15G /var/lib/docker/overlay2 17M /var/lib/docker/image 242M /var/lib/docker/volumes 0 /var/lib/docker/trust 108K /var/lib/docker/network 0 /var/lib/docker/swarm 16K /var/lib/docker/builder 56K /var/lib/docker/buildkit 0 /var/lib/docker/tmp 0 /var/lib/docker/runtimes 15G /var/lib/docker/ 得到的确是</description>
    </item>
    
    <item>
      <title>安装单节点Ceph集群</title>
      <link>https://junetalk.github.io/2019/11/24/install-ceph-sinle-node/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/24/install-ceph-sinle-node/</guid>
      <description>本文主要记录在虚拟机中安装Ceph单节点集群的过程，其实多配置几个节点，也就是安装集群的过程。 Ceph中午文档：http://docs.ce</description>
    </item>
    
    <item>
      <title>PostgreSQL安装并测试file_fdw</title>
      <link>https://junetalk.github.io/2019/11/22/install-file-fdw-for-postgresql/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/22/install-file-fdw-for-postgresql/</guid>
      <description>file_fdw模块提供了外部数据封装器，可以用来在服务器的文件系统中访问数据文件。本文主要是记录安装file_fdw模块的过程，并做测试。</description>
    </item>
    
    <item>
      <title>PostgreSQL安装并测试mysql_fdw</title>
      <link>https://junetalk.github.io/2019/11/22/install-mysql-fdw-for-postgresql/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/22/install-mysql-fdw-for-postgresql/</guid>
      <description>mysql_fdw PostgreSQL外部MySQL表功能的扩展，所谓外部表，就是在PG数据库中通过SQL访问外部数据源数据，就像访问本地数据库一样，下面就</description>
    </item>
    
    <item>
      <title>安装Greenplum数据库集群</title>
      <link>https://junetalk.github.io/2019/11/20/install-greenplum-cluster/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/20/install-greenplum-cluster/</guid>
      <description>本文主要介绍如何快速安装部署单节点的Greenplum过程，以及Greenplum的一些常用命令及工具。 环境准备 环境说明 操作系统：Cento</description>
    </item>
    
    <item>
      <title>Kubernetes存储之Volume</title>
      <link>https://junetalk.github.io/2019/11/12/kubernetes-storage-volumes/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/12/kubernetes-storage-volumes/</guid>
      <description>容器和Pod生命周期可能很短，会被频繁销毁和创建。容器销毁时，保存在容器的内部文件系统中的数据都会被清楚。 为了持久化保存容器的数据，可以使用</description>
    </item>
    
    <item>
      <title>Kubernetes资源对象之ConfigMap</title>
      <link>https://junetalk.github.io/2019/11/11/kubernetes-resource-configmap/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/11/kubernetes-resource-configmap/</guid>
      <description>在实际的应用部署中，经常需要为各种应用/中间件配置各种参数，如数据库地址、用 户名、密码等， 而且大多数生产环境中的应用程序配置较为复杂，可能是</description>
    </item>
    
    <item>
      <title>Kubernetes资源对象之Pod</title>
      <link>https://junetalk.github.io/2019/11/10/kubernetes-resource-pod/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/10/kubernetes-resource-pod/</guid>
      <description>基本概念 Pod是Kubernetes集群中最基本的资源对象。每个Pod由一个或多个业务容器和一个根容器(Pause容器)组成。 Kuberne</description>
    </item>
    
    <item>
      <title>Kubernetes资源对象之Secret</title>
      <link>https://junetalk.github.io/2019/11/10/kubernetes-resource-secret/</link>
      <pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/10/kubernetes-resource-secret/</guid>
      <description>Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 ssh key。将这些信息放在 secret 中比放在 pod 的定义中或者 docker 镜像中来说更加安全和灵活。 Secre</description>
    </item>
    
    <item>
      <title>Helm安装Rancher并配置DNS01校验证书</title>
      <link>https://junetalk.github.io/2019/11/07/rancher-tls-with-letsencrypt-dns01/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/07/rancher-tls-with-letsencrypt-dns01/</guid>
      <description>版本说明 版本说明： Rancher：v2.3.5 Cert-Manager：v0.12.0 Rancher Chart源码 Rancher Chart源码在 https://github.com/rancher/rancher/tree/master/chart ，当前ranche</description>
    </item>
    
    <item>
      <title>使用Cert Manager生成Let’s Encrypt证书</title>
      <link>https://junetalk.github.io/2019/11/04/using-cert-manager-with-nginx-ingress/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/04/using-cert-manager-with-nginx-ingress/</guid>
      <description>安装 Cert Manager 参考 安装Cert Manager ，进行安装。 Let’s Encrypt 证书颁发原理 Let’s Encrypt 利用 ACME 协议来校验域名是否真的属于你，校验成功后就可以自动颁发免费证</description>
    </item>
    
    <item>
      <title>安装Cert Manager</title>
      <link>https://junetalk.github.io/2019/11/02/install-cert-manager/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/02/install-cert-manager/</guid>
      <description>参考官方文档： https://docs.cert-manager.io/en/latest/getting-started/install/kubernetes.html 创建命名空间 1 kubectl create namespace cert-manager cert-manager 部署时会生成 ValidatingWebhookConfiguration 注册ValidatingAdmissionWebhook 来实现 CRD 校验，而Validat</description>
    </item>
    
    <item>
      <title>使用Helm安装Drone并集成Gitea</title>
      <link>https://junetalk.github.io/2019/11/01/install-gitea-and-drone-with-helm/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/11/01/install-gitea-and-drone-with-helm/</guid>
      <description>首先安装Gitea，再安装Drone 安装Gitea 创建证书 参考 使用Cert Manager配置Let’s Encrypt证书 ，先要创建一个Clu</description>
    </item>
    
    <item>
      <title>使用Helm安装Harbor</title>
      <link>https://junetalk.github.io/2019/10/31/install-harbor-with-helm/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/10/31/install-harbor-with-helm/</guid>
      <description>Harbor是构建企业级私有docker镜像的仓库的开源解决方案，它是Docker Registry的更高级封装，它除了提供友好的Web UI界</description>
    </item>
    
    <item>
      <title>安装Helm</title>
      <link>https://junetalk.github.io/2019/10/31/install-helm/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/10/31/install-helm/</guid>
      <description>Helm 是由 Deis 发起的一个开源工具，有助于简化部署和管理 Kubernetes 应用。本文主要是记录Helm 2的安装过程。 Helm镜像 Helm官方镜像：https://k</description>
    </item>
    
    <item>
      <title>使用Kubeadm安装单节点kubernetes</title>
      <link>https://junetalk.github.io/2019/10/30/install-single-k8s-with-kubeadm/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/10/30/install-single-k8s-with-kubeadm/</guid>
      <description>本文使用Kubeadm来安装一个单节点的Kubernetes环境，以加深对Kubernetes各个组件和安装过程的理解。 环境准备 请参考 使用R</description>
    </item>
    
    <item>
      <title>使用RKE安装单节点kubernetes</title>
      <link>https://junetalk.github.io/2019/10/30/install-single-k8s-with-rke/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/10/30/install-single-k8s-with-rke/</guid>
      <description>Kubernetes 是Google的一种基于容器的开源服务编排解决方案。在我们进行Kubernetes的学习前，为了对Kubernetes的工作原理有一个大概</description>
    </item>
    
    <item>
      <title>Tengine&#43;Lua&#43;GraphicsMagick动态裁剪图片</title>
      <link>https://junetalk.github.io/2019/08/10/tengine-lua-graphicsMagick-resize-picture/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/08/10/tengine-lua-graphicsMagick-resize-picture/</guid>
      <description>软件列表 Tengine：https://github.com/alibaba/tengine Lua：http://www.lua.org/f</description>
    </item>
    
    <item>
      <title>网络通信协议</title>
      <link>https://junetalk.github.io/2019/07/27/internet-protocal/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/07/27/internet-protocal/</guid>
      <description>1 网络通信 1.1 协议 TCP/IP UDP/IP Multcast 单播.每次只有两个实体相互通信，发送端和接收端都是唯一确定的 IP4中，0.0.0.0到223.255.255.255属</description>
    </item>
    
    <item>
      <title>Docker搭建hadoop和hive环境</title>
      <link>https://junetalk.github.io/2019/07/26/install-hadoop-and-hive-with-docker/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/07/26/install-hadoop-and-hive-with-docker/</guid>
      <description>文将介绍如何在docker上从零开始安装hadoop以及hive环境。本文不会介绍如何安装docker，也不会过多的介绍docker各个命令</description>
    </item>
    
    <item>
      <title>安装阿波罗配置中心</title>
      <link>https://junetalk.github.io/2019/07/15/apollo/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/07/15/apollo/</guid>
      <description>安装 安装阿波罗 1、 在虚拟机安装git和mysql 1 yum install git mysql -y 2、克隆安装脚本 1 git clone https://github.com/nobodyiam/apollo-build-scripts.git 3、配置数据策略 在虚拟机访问mysql，然后初始化数据：</description>
    </item>
    
    <item>
      <title>LVS负载均衡</title>
      <link>https://junetalk.github.io/2019/06/29/lvs/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/06/29/lvs/</guid>
      <description>1、介绍 ​ 负载均衡(Load Balance)是一种服务器或网络设备的集群技术。负载均衡将特定的业务(网络服务、网络流量等)分担给多个服务器或</description>
    </item>
    
    <item>
      <title>Nginx服务器</title>
      <link>https://junetalk.github.io/2019/06/29/nginx/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/06/29/nginx/</guid>
      <description>1、常用Web服务器介绍 apache、Nginx、tomcat、weblogic、iis、jboss、websphere、jetty、net</description>
    </item>
    
    <item>
      <title>不使用Eureka创建Spring Cloud微服务</title>
      <link>https://junetalk.github.io/2019/04/19/spring-cloud-eureka-service-discovery-and-register-example/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/04/19/spring-cloud-eureka-service-discovery-and-register-example/</guid>
      <description>首先创建一个普通项目，分为生产者和消费者两部分，然后在逐步集成SpringCloud的相关组件。 1、创建基本应用 1.1、创建工程 创建spri</description>
    </item>
    
    <item>
      <title>Spring Cloud之Eureka配置示例</title>
      <link>https://junetalk.github.io/2019/04/15/spring-cloud-eureka-config-example/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2019/04/15/spring-cloud-eureka-config-example/</guid>
      <description>Eureka是Netflix开源的服务发现组件，本身是一个基于REST的服务，包含Server和Client两部分，Spring Cloud将</description>
    </item>
    
    <item>
      <title>UML类之间关系</title>
      <link>https://junetalk.github.io/2016/04/01/uml-class-realation/</link>
      <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2016/04/01/uml-class-realation/</guid>
      <description>前面两篇文章讲到了使用PlantUML来画类图，要想准确地画出类与类之间的关系，必须理清类和类之间的关系。类的关系有泛化(Generaliz</description>
    </item>
    
    <item>
      <title>PlantUML安装和使用</title>
      <link>https://junetalk.github.io/2016/02/29/plantuml-install-and-usage/</link>
      <pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2016/02/29/plantuml-install-and-usage/</guid>
      <description>什么是PlantUML PlantUML是一个快速创建UML图形的组件，PlantUML支持的图形有： sequence diagram, use case diagram, class diagram, activity diagram, component diagram, state diagram, object diagram, wireframe graphical interface Pl</description>
    </item>
    
    <item>
      <title>PlantUML类图</title>
      <link>https://junetalk.github.io/2016/02/29/plantuml-class-diagram/</link>
      <pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2016/02/29/plantuml-class-diagram/</guid>
      <description>类之间的关系 PlantUML用下面的符号来表示类之间的关系： 泛化，Generalization：&amp;lt;|-- 关联，Association：</description>
    </item>
    
    <item>
      <title>Scala Reading List</title>
      <link>https://junetalk.github.io/2016/01/23/scala-reading-list/</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2016/01/23/scala-reading-list/</guid>
      <description>学习教程 为 Java程序员准备的Scala教程 Scala 初学指南：本书是 The Neophyte&amp;rsquo;s Guide to Scala 的中文翻译，是 Daniel Westheide 写的一系列有关 Scala 的文章。 http://ifeve.com/tag/scala/ Scala 指南：开始精彩的Sca</description>
    </item>
    
    <item>
      <title>Bash条件判断</title>
      <link>https://junetalk.github.io/2015/07/08/bash-if-else/</link>
      <pubDate>Wed, 08 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/07/08/bash-if-else/</guid>
      <description>每个完整并且合理的程序语言都具有条件判断的功能，并且可以根据条件测试的结果做下一步的处理。Bash有test命令、各种中括号和圆括号操作，和</description>
    </item>
    
    <item>
      <title>Bash中的变量</title>
      <link>https://junetalk.github.io/2015/07/07/bash-variable/</link>
      <pubDate>Tue, 07 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/07/07/bash-variable/</guid>
      <description>变量是脚本编程中进行数据表现的一种方法。说白了，变量不过是计算机为了保留数据项，而在内存中分配的一个位置或一组位置的标识或名字。变量既可以出</description>
    </item>
    
    <item>
      <title>Bash中的特殊字符</title>
      <link>https://junetalk.github.io/2015/07/06/bash-special-characters/</link>
      <pubDate>Mon, 06 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/07/06/bash-special-characters/</guid>
      <description>Bash中，用在脚本和其他地方的字符叫做特殊字符。下面依次举例介绍每个字符的用途。 # 行首以#(#!是个例外)开头是注释。 1 # This line is a comment. 注释也</description>
    </item>
    
    <item>
      <title>高级Bash脚本编程入门</title>
      <link>https://junetalk.github.io/2015/06/29/advanced-bash-script-programming/</link>
      <pubDate>Mon, 29 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/29/advanced-bash-script-programming/</guid>
      <description>最近在看《Advanced Bash Scripting Guide》这本书，第二章举了一个清除日志的例子，来讲述如何使用Bash进行编程并聊到了一些编程规范。本文主要</description>
    </item>
    
    <item>
      <title>spark-shell脚本分析</title>
      <link>https://junetalk.github.io/2015/06/26/spark-shell-command/</link>
      <pubDate>Fri, 26 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/26/spark-shell-command/</guid>
      <description>本文主要分析spark-shell脚本的运行逻辑，涉及到spark-submit、spark-class等脚本的分析，希望通过分析脚本以了解</description>
    </item>
    
    <item>
      <title>Scala中的对象</title>
      <link>https://junetalk.github.io/2015/06/19/scala-object/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/19/scala-object/</guid>
      <description>Scala中没有静态方法或静态字段，但可以使用object这个语法结构来实现相同的功能。对象与类在语法层面上很相似，除了不能提供构造器参数外</description>
    </item>
    
    <item>
      <title>Scala中的类</title>
      <link>https://junetalk.github.io/2015/06/19/scala-class/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/19/scala-class/</guid>
      <description>阅读《Programming in Scala》，整理Scala类、继承、重载相关的一些知识点。 类 Scala使用class来定义类。 1 2 3 4 5 class Counter</description>
    </item>
    
    <item>
      <title>使用Scala高价函数简化代码</title>
      <link>https://junetalk.github.io/2015/06/18/simplify-code-using-scala-higher-order-function/</link>
      <pubDate>Thu, 18 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/18/simplify-code-using-scala-higher-order-function/</guid>
      <description>在Scala里，带有其他函数做参数的函数叫做高阶函数，使用高阶函数可以简化代码。 减少重复代码 有这样一段代码，查找当前目录样以某一个字符串结尾</description>
    </item>
    
    <item>
      <title>推荐系统笔记</title>
      <link>https://junetalk.github.io/2015/06/15/note-about-recommendation-system/</link>
      <pubDate>Mon, 15 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/15/note-about-recommendation-system/</guid>
      <description>1、产生原因 信息过载 无明确需求 2、什么是推荐？ 在信息过载又没有明确需求的情况下，找到用户感兴趣的东西。 《Mahout实战》上的定义是：推荐就</description>
    </item>
    
    <item>
      <title>使用Mahout实现协同过滤</title>
      <link>https://junetalk.github.io/2015/06/10/collaborative-filtering-using-mahout/</link>
      <pubDate>Wed, 10 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/10/collaborative-filtering-using-mahout/</guid>
      <description>Mahout算法框架自带的推荐器有下面这些： GenericUserBasedRecommender：基于用户的推荐器，用户数量少时速度快； G</description>
    </item>
    
    <item>
      <title>Spark On YARN内存分配</title>
      <link>https://junetalk.github.io/2015/06/09/memory-in-spark-on-yarn/</link>
      <pubDate>Tue, 09 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/09/memory-in-spark-on-yarn/</guid>
      <description>本文主要了解Spark On YARN部署模式下的内存分配情况，因为没有深入研究Spark的源代码，所以只能根据日志去看相关的源代码，从而了解“为</description>
    </item>
    
    <item>
      <title>Spark配置参数</title>
      <link>https://junetalk.github.io/2015/06/07/spark-configuration/</link>
      <pubDate>Sun, 07 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/07/spark-configuration/</guid>
      <description>以下是整理的Spark中的一些配置参数，官方文档请参考Spark Configuration。 Spark提供三个位置用来配置系统： Spark属</description>
    </item>
    
    <item>
      <title>YARN的内存和CPU配置</title>
      <link>https://junetalk.github.io/2015/06/05/yarn-memory-and-cpu-configuration/</link>
      <pubDate>Fri, 05 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/05/yarn-memory-and-cpu-configuration/</guid>
      <description>Hadoop YARN同时支持内存和CPU两种资源的调度，本文介绍如何配置YARN对内存和CPU的使用。 YARN作为一个资源调度器，应该考虑到集群里面每</description>
    </item>
    
    <item>
      <title>如何使用Spark ALS实现协同过滤</title>
      <link>https://junetalk.github.io/2015/06/01/how-to-implement-collaborative-filtering-using-spark-als/</link>
      <pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/06/01/how-to-implement-collaborative-filtering-using-spark-als/</guid>
      <description>本文主要记录最近一段时间学习和实现Spark MLlib中的协同过滤的一些总结，希望对大家熟悉Spark ALS算法有所帮助。 更新： 【2016.</description>
    </item>
    
    <item>
      <title>安装和配置Sentry</title>
      <link>https://junetalk.github.io/2015/04/30/install-and-config-sentry/</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/30/install-and-config-sentry/</guid>
      <description>本文主要记录安装和配置Sentry的过程，关于Sentry的介绍，请参考Apache Sentry架构介绍。 1. 环境说明 系统环境： 操作系统：Ce</description>
    </item>
    
    <item>
      <title>测试Hive集成Sentry</title>
      <link>https://junetalk.github.io/2015/04/30/test-hive-with-sentry/</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/30/test-hive-with-sentry/</guid>
      <description>本文在安装和配置Sentry基础之上测试Hive集成Sentry。注意：这里Hive中并没有配置Kerberos认证。 关于配置了Kerber</description>
    </item>
    
    <item>
      <title>Apache Sentry架构介绍</title>
      <link>https://junetalk.github.io/2015/04/29/apache-sentry-architecture/</link>
      <pubDate>Wed, 29 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/29/apache-sentry-architecture/</guid>
      <description>介绍 Apache Sentry是Cloudera公司发布的一个Hadoop开源组件，截止目前还是Apache的孵化项目，它提供了细粒度级、基于角色的授权</description>
    </item>
    
    <item>
      <title>编译CDH Spark源代码</title>
      <link>https://junetalk.github.io/2015/04/28/compile-cdh-spark-source-code/</link>
      <pubDate>Tue, 28 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/28/compile-cdh-spark-source-code/</guid>
      <description>本文以Cloudera维护的Spark分支项目为例，记录跟新Spark分支以及编译Spark源代码的过程。 下载代码 在Github上fork C</description>
    </item>
    
    <item>
      <title>Spark MLlib中的协同过滤</title>
      <link>https://junetalk.github.io/2015/04/17/spark-mllib-collaborative-filtering/</link>
      <pubDate>Fri, 17 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/17/spark-mllib-collaborative-filtering/</guid>
      <description>本文主要通过Spark官方的例子理解ALS协同过滤算法的原理和编码过程，然后通过对电影进行推荐来熟悉一个完整的推荐过程。 协同过滤 协同过滤常被</description>
    </item>
    
    <item>
      <title>Spark SQL中的数据源</title>
      <link>https://junetalk.github.io/2015/04/03/spark-sql-datasource/</link>
      <pubDate>Fri, 03 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/04/03/spark-sql-datasource/</guid>
      <description>Spark 支持通过 DataFrame 来操作大量的数据源，包括外部文件（如 json、avro、parquet、sequencefile 等等）、hive、关系数据库、c</description>
    </item>
    
    <item>
      <title>Reading List 2015-03</title>
      <link>https://junetalk.github.io/2015/03/30/reading-list-2015-03/</link>
      <pubDate>Mon, 30 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/03/30/reading-list-2015-03/</guid>
      <description>这个月主要在关注流式处理和推荐系统方面的技术。如何从零构建一个推荐系统？网上能找到的有指导意义的资料太少，只能一点点摸索？ Spark LeanCloud 离线数据分析功</description>
    </item>
    
    <item>
      <title>Spark本地模式运行</title>
      <link>https://junetalk.github.io/2015/03/30/spark-test-in-local-mode/</link>
      <pubDate>Mon, 30 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/03/30/spark-test-in-local-mode/</guid>
      <description>Spark的安装分为几种模式，其中一种是本地运行模式，只需要在单节点上解压即可运行，这种模式不需要依赖Hadoop 环境。在本地运行模式中，m</description>
    </item>
    
    <item>
      <title>Spark SQL中的DataFrame</title>
      <link>https://junetalk.github.io/2015/03/26/spark-sql-dataframe/</link>
      <pubDate>Thu, 26 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/03/26/spark-sql-dataframe/</guid>
      <description>在2014年7月1日的 Spark Summit 上，Databricks 宣布终止对 Shark 的开发，将重点放到 Spark SQL 上。在会议上，Databricks 表示，Shark 更多是</description>
    </item>
    
    <item>
      <title>将Avro数据转换为Parquet格式</title>
      <link>https://junetalk.github.io/2015/03/25/converting-avro-data-to-parquet-format/</link>
      <pubDate>Wed, 25 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/03/25/converting-avro-data-to-parquet-format/</guid>
      <description>本文主要测试将Avro数据转换为Parquet格式的过程并查看 Parquet 文件的 schema 和元数据。 准备 将文本数据转换为 Parquet 格式并读取内容，可以参考 Cloudera 的 MapReduce 例子：</description>
    </item>
    
    <item>
      <title>如何将Avro数据加载到Spark</title>
      <link>https://junetalk.github.io/2015/03/24/how-to-load-some-avro-data-into-spark/</link>
      <pubDate>Tue, 24 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/03/24/how-to-load-some-avro-data-into-spark/</guid>
      <description>这是一篇翻译，原文来自：How to load some Avro data into Spark。 首先，为什么使用 Avro ？ 最基本的格式是 CSV ，其廉价并且不需要顶一个一个 schema 和数据关联。 随后流行</description>
    </item>
    
    <item>
      <title>安装和配置Hue</title>
      <link>https://junetalk.github.io/2015/02/28/install-and-config-hue/</link>
      <pubDate>Sat, 28 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/28/install-and-config-hue/</guid>
      <description>本文主要记录使用 yum 源安装 Hue 以及配置 Hue 集成 Hdfs、Hive、Impala、Yarn、Kerberos、LDAP、Sentry、Solr 等的过</description>
    </item>
    
    <item>
      <title>Hadoop Streaming 原理</title>
      <link>https://junetalk.github.io/2015/02/12/hadoop-streaming/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/12/hadoop-streaming/</guid>
      <description>简介 Hadoop Streaming 是 Hadoop 提供的一个 MapReduce 编程工具，它允许用户使用任何可执行文件、脚本语言或其他编程语言来实现 Mapper 和 Reducer，从而充分利用 Hadoop 并行计算框架的</description>
    </item>
    
    <item>
      <title>Reading List 2015-02</title>
      <link>https://junetalk.github.io/2015/02/10/reading-list-2015-02/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/10/reading-list-2015-02/</guid>
      <description>一直有个想法没有付诸实践，想做个分享知识的网站，类似 Leanote、开发者头条、GitHunt 等等的可检索的有思想的一个产品。作为尝试，在想</description>
    </item>
    
    <item>
      <title>Useful Hadoop Commands</title>
      <link>https://junetalk.github.io/2015/02/10/useful-commands-in-hadoop/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/10/useful-commands-in-hadoop/</guid>
      <description>hadoop 解压 gz 文件到文本文件 1 $ hadoop fs -text /hdfs_path/compressed_file.gz | hadoop fs -put - /tmp/uncompressed-file.txt 解压本地文件 gz 文件并上传到 hdfs 1 $ gunzip -c filename.txt.gz | hadoop fs -put - /tmp/filename.txt 使用 awk 处理 csv 文件，参考 Using awk and friends with Hadoop: 1 $ hadoop fs -cat</description>
    </item>
    
    <item>
      <title>如何在CDH5上运行Spark应用</title>
      <link>https://junetalk.github.io/2015/02/04/how-to-run-a-simple-apache-spark-app-in-cdh-5/</link>
      <pubDate>Wed, 04 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/04/how-to-run-a-simple-apache-spark-app-in-cdh-5/</guid>
      <description>这篇文章参考 How-to: Run a Simple Apache Spark App in CDH 5 编写而成，没有完全参照原文翻译，而是重新进行了整理，例如：spark 版本改为 1.3.0，添加了 Python 版的程序。 创</description>
    </item>
    
    <item>
      <title>Spark编程指南笔记</title>
      <link>https://junetalk.github.io/2015/02/03/spark-programming-guide/</link>
      <pubDate>Tue, 03 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/02/03/spark-programming-guide/</guid>
      <description>本文是参考Spark官方编程指南（Spark 版本为1.2）整理出来的学习笔记，主要是用于加深对 Spark 的理解，并记录一些知识点。 1. Spark介绍 S</description>
    </item>
    
    <item>
      <title>安装和部署Presto</title>
      <link>https://junetalk.github.io/2015/01/26/install-and-deploy-presto/</link>
      <pubDate>Mon, 26 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/01/26/install-and-deploy-presto/</guid>
      <description>1. 安装环境 操作系统：CentOs6.5 Hadoop 集群：CDH5.3 JDK 版本：jdk1.8.0_31 为了测试简单，我是将 Presto 的 coordinator 和 worker 都部署在 cdh1 节点上，并且</description>
    </item>
    
    <item>
      <title>CDH 5.2中Impala认证集成LDAP和Kerberos</title>
      <link>https://junetalk.github.io/2015/01/23/new-in-cdh-5-2-impala-authentication-with-ldap-and-kerberos/</link>
      <pubDate>Fri, 23 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/01/23/new-in-cdh-5-2-impala-authentication-with-ldap-and-kerberos/</guid>
      <description>这是一篇翻译的文章，原文为 New in CDH 5.2: Impala Authentication with LDAP and Kerberos。由于翻译水平有限，难免会一些翻译不准确的地方，欢迎指正！ Impala 认证现在可以通过 LDAP 和</description>
    </item>
    
    <item>
      <title>Presto介绍</title>
      <link>https://junetalk.github.io/2015/01/23/presto-overview/</link>
      <pubDate>Fri, 23 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2015/01/23/presto-overview/</guid>
      <description>1. 简介 Presto 是一个运行在集群之上的分布式系统。一个完全的安装报考一个 coordinator 进程和多个 workers 进程。查询通过一个客户端例如 Presto CLI 提交到 coordinator 进程。这个 coordinator 进程解析、</description>
    </item>
    
    <item>
      <title>Hadoop集群部署权限总结</title>
      <link>https://junetalk.github.io/2014/11/25/quikstart-for-config-kerberos-ldap-and-sentry-in-hadoop/</link>
      <pubDate>Tue, 25 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/25/quikstart-for-config-kerberos-ldap-and-sentry-in-hadoop/</guid>
      <description>这是一篇总结的文章，主要介绍 Hadoop 集群快速部署权限的步骤以及一些注意事项。如果你想了解详细的过程，请参考本博客中其他的文章。 1. 开始之前 hadoop 集群一共</description>
    </item>
    
    <item>
      <title>Zookeeper配置Kerberos认证</title>
      <link>https://junetalk.github.io/2014/11/18/config-kerberos-in-cdh-zookeeper/</link>
      <pubDate>Tue, 18 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/18/config-kerberos-in-cdh-zookeeper/</guid>
      <description>参考 使用yum安装CDH Hadoop集群 安装 hadoop 集群，集群包括三个节点，每个节点的ip、主机名和部署的组件分配如下： 1 2 3 192.168.56.121 cdh1 NameNode</description>
    </item>
    
    <item>
      <title>配置安全的Hive集群集成Sentry</title>
      <link>https://junetalk.github.io/2014/11/14/config-secured-hive-with-sentry/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/14/config-secured-hive-with-sentry/</guid>
      <description>本文主要记录配置安全的Hive集群集成Sentry的过程。Hive上配置了Kerberos认证，配置的过程请参考： 使用yum安装CDH Had</description>
    </item>
    
    <item>
      <title>配置安全的Impala集群集成Sentry</title>
      <link>https://junetalk.github.io/2014/11/14/config-secured-impala-with-sentry/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/14/config-secured-impala-with-sentry/</guid>
      <description>本文主要记录配置安全的Impala集群集成Sentry的过程。Impala集群上配置了Kerberos认证，并且需要提前配置好Hive与Ke</description>
    </item>
    
    <item>
      <title>Hadoop配置LDAP集成Kerberos</title>
      <link>https://junetalk.github.io/2014/11/12/config-ldap-with-kerberos-in-cdh-hadoop/</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/12/config-ldap-with-kerberos-in-cdh-hadoop/</guid>
      <description>本文主要记录 cdh hadoop 集群集成 ldap 的过程，这里 ldap 安装的是 OpenLDAP 。LDAP 用来做账号管理，Kerberos作为认证。授权一般来说是由应用来决定的，通过在 LDAP</description>
    </item>
    
    <item>
      <title>Hive配置Kerberos认证</title>
      <link>https://junetalk.github.io/2014/11/06/config-kerberos-in-cdh-hive/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/06/config-kerberos-in-cdh-hive/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>Impala配置Kerberos认证</title>
      <link>https://junetalk.github.io/2014/11/06/config-kerberos-in-cdh-impala/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/06/config-kerberos-in-cdh-impala/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>YARN配置Kerberos认证</title>
      <link>https://junetalk.github.io/2014/11/05/config-kerberos-in-cdh-yarn/</link>
      <pubDate>Wed, 05 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/05/config-kerberos-in-cdh-yarn/</guid>
      <description>关于 Kerberos 的安装和 HDFS 配置 kerberos 认证，请参考 HDFS配置kerberos认证。 1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.</description>
    </item>
    
    <item>
      <title>HDFS配置Kerberos认证</title>
      <link>https://junetalk.github.io/2014/11/04/config-kerberos-in-cdh-hdfs/</link>
      <pubDate>Tue, 04 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/11/04/config-kerberos-in-cdh-hdfs/</guid>
      <description>本文主要记录 CDH Hadoop 集群上配置 HDFS 集成 Kerberos 的过程，包括 Kerberos 的安装和 Hadoop 相关配置修改说明。 1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：C</description>
    </item>
    
    <item>
      <title>Impala查询功能测试</title>
      <link>https://junetalk.github.io/2014/10/24/impala-query-table-tutorial/</link>
      <pubDate>Fri, 24 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/10/24/impala-query-table-tutorial/</guid>
      <description>关于 Impala 使用方法的一些测试，包括加载数据、查看数据库、聚合关联查询、子查询等等。 1. 准备测试数据 以下测试以 impala 用户来运行： 1 2 3 4 5 6 7 8 9 10 $ su</description>
    </item>
    
    <item>
      <title>当前数据仓库建设过程</title>
      <link>https://junetalk.github.io/2014/10/23/hive-warehouse-in-2014/</link>
      <pubDate>Thu, 23 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/10/23/hive-warehouse-in-2014/</guid>
      <description>一个典型的企业数据仓库通常包含数据采集、数据加工和存储、数据展现等几个过程，本篇文章将按照这个顺序记录部门当前建设数据仓库的过程。 1. 数据采集</description>
    </item>
    
    <item>
      <title>Mahout推荐引擎介绍</title>
      <link>https://junetalk.github.io/2014/09/22/mahout-recommend-engine/</link>
      <pubDate>Mon, 22 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/09/22/mahout-recommend-engine/</guid>
      <description>Mahout 是一个来自 Apache 的、开源的机器学习软件库，他主要关注于推荐引擎（协同过滤）、聚类和分类。 推荐一般是基于物品或者用户进行推荐相关。 聚类是讲大量的</description>
    </item>
    
    <item>
      <title>Llama的使用</title>
      <link>https://junetalk.github.io/2014/09/09/llama/</link>
      <pubDate>Tue, 09 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/09/09/llama/</guid>
      <description>1. 介绍 Llama (Low Latency Application MAster) 是一个 Yarn 的 Application Master，用于协调 Impala 和 Yarn 之间的集群资源的管理和监控。Llama 使 Impala 能够获取、使用和释放资源配额，而不需要 Impala 使</description>
    </item>
    
    <item>
      <title>升级cdh4到cdh5</title>
      <link>https://junetalk.github.io/2014/08/19/upgrading-from-cdh4-to-cdh5/</link>
      <pubDate>Tue, 19 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/08/19/upgrading-from-cdh4-to-cdh5/</guid>
      <description>本文主要记录从CDH4升级到CDH5的过程和遇到的问题，当然本文同样适用于CDH5低版本向最新版本的升级。 1. 不兼容的变化 升级前，需要注意 cdh5 有</description>
    </item>
    
    <item>
      <title>Sqoop导入关系数据库到Hive</title>
      <link>https://junetalk.github.io/2014/08/04/import-data-to-hive-with-sqoop/</link>
      <pubDate>Mon, 04 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/08/04/import-data-to-hive-with-sqoop/</guid>
      <description>Sqoop 是 apache 下用于 RDBMS 和 HDFS 互相导数据的工具。本文以 mysql 数据库为例，实现关系数据库导入到 hdfs 和 hive。 1. 安装 Sqoop 使用 rpm 安装即可。 1 yum install sqoop sqoop-metastore -y 安装完之后需要</description>
    </item>
    
    <item>
      <title>2014年7月总结</title>
      <link>https://junetalk.github.io/2014/07/31/summary-of-july-in-2014/</link>
      <pubDate>Thu, 31 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/31/summary-of-july-in-2014/</guid>
      <description>在休息了将近三个月之后，7月9日终于开始上班了，新的工作还是和 hadoop 相关。7月主要的工作内容如下： 搭建新的 hadoop 集群，hadoop 版本为 CDH4.7</description>
    </item>
    
    <item>
      <title>Phoenix Quick Start</title>
      <link>https://junetalk.github.io/2014/07/28/phoenix-quick-start/</link>
      <pubDate>Mon, 28 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/28/phoenix-quick-start/</guid>
      <description>1. 介绍 Phoenix 是 Salesforce.com 开源的一个 Java 中间件，可以让开发者在Apache HBase 上执行 SQL 查询。Phoenix完全使用Java编写，代码位于 GitHub 上，并且提供了一个客</description>
    </item>
    
    <item>
      <title>采集日志到Hive</title>
      <link>https://junetalk.github.io/2014/07/25/collect-log-to-hive/</link>
      <pubDate>Fri, 25 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/25/collect-log-to-hive/</guid>
      <description>我们现在的需求是需要将线上的日志以小时为单位采集并存储到 hive 数据库中，方便以后使用 mapreduce 或者 impala 做数据分析。为了实现这个目标调研了 flume 如何采集数据到 h</description>
    </item>
    
    <item>
      <title>Flume-ng的原理和使用</title>
      <link>https://junetalk.github.io/2014/07/22/flume-ng/</link>
      <pubDate>Tue, 22 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/22/flume-ng/</guid>
      <description>1. 介绍 Flume NG是Cloudera提供的一个分布式、可靠、可用的系统，它能够将不同数据源的海量日志数据进行高效收集、聚合、移动，最后存储到一个中</description>
    </item>
    
    <item>
      <title>CDH中配置HDFS HA</title>
      <link>https://junetalk.github.io/2014/07/18/install-hdfs-ha-in-cdh/</link>
      <pubDate>Fri, 18 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/18/install-hdfs-ha-in-cdh/</guid>
      <description>最近又安装 hadoop 集群， 故尝试了一下配置 HDFS 的 HA，CDH4支持Quorum-based Storage和shared storage using NFS两种HA方案，而CDH</description>
    </item>
    
    <item>
      <title>Spark集群安装和使用</title>
      <link>https://junetalk.github.io/2014/07/01/spark-install-and-usage/</link>
      <pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/07/01/spark-install-and-usage/</guid>
      <description>本文主要记录 CDH5 集群中 Spark 集群模式的安装过程配置过程并测试 Spark 的一些基本使用方法。 安装环境如下： 操作系统：CentOs 6.5 Hadoop 版本：cdh-5.4.0</description>
    </item>
    
    <item>
      <title>HBase中的一些注意事项</title>
      <link>https://junetalk.github.io/2014/06/26/some-tips-about-hbase/</link>
      <pubDate>Thu, 26 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/26/some-tips-about-hbase/</guid>
      <description>1. 安装集群前 配置SSH无密码登陆 DNS。HBase使用本地 hostname 才获得IP地址，正反向的DNS都是可以的。你还可以设置 hbase.regionserver.dns.interface 来指定主接口，设置 hbase.regionserver.dns.nameserver 来指</description>
    </item>
    
    <item>
      <title>HBase和Cassandra比较</title>
      <link>https://junetalk.github.io/2014/06/24/hbase-vs-cassandra/</link>
      <pubDate>Tue, 24 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/24/hbase-vs-cassandra/</guid>
      <description>HBase是一个开源的分布式存储系统。他可以看作是Google的Bigtable的开源实现。如同Google的Bigtable使用Googl</description>
    </item>
    
    <item>
      <title>MapReduce任务参数调优</title>
      <link>https://junetalk.github.io/2014/06/24/tuning-in-mapreduce/</link>
      <pubDate>Tue, 24 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/24/tuning-in-mapreduce/</guid>
      <description>本文主要记录Hadoop 2.x版本中MapReduce参数调优，不涉及Yarn的调优。 Hadoop的默认配置文件（以cdh5.0.1为例）：</description>
    </item>
    
    <item>
      <title>MapReduce任务运行过程</title>
      <link>https://junetalk.github.io/2014/06/24/the-running-process-of-mapreduce-job/</link>
      <pubDate>Tue, 24 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/24/the-running-process-of-mapreduce-job/</guid>
      <description>Map-Reduce的处理过程主要涉及以下四个部分： 客户端Client：用于提交Map-reduce任务job JobTracker：协调整个</description>
    </item>
    
    <item>
      <title>Hive中的排序语法</title>
      <link>https://junetalk.github.io/2014/06/22/sort-in-hive-query/</link>
      <pubDate>Sun, 22 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/22/sort-in-hive-query/</guid>
      <description>ORDER BY hive中的ORDER BY语句和关系数据库中的sql语法相似。他会对查询结果做全局排序，这意味着所有的数据会传送到一个Reduce任务上</description>
    </item>
    
    <item>
      <title>Storm集群安装部署步骤</title>
      <link>https://junetalk.github.io/2014/06/19/how-to-install-and-deploy-a-storm-cluster/</link>
      <pubDate>Thu, 19 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/19/how-to-install-and-deploy-a-storm-cluster/</guid>
      <description>开始学习Storm，本文主要记录Storm集群安装部署步骤，不包括对Storm的介绍。 安装storm集群，需要依赖以下组件： Zookeeper Python Zeromq Storm JDK JZMQ 故安</description>
    </item>
    
    <item>
      <title>HBase源码分析：HTable put过程</title>
      <link>https://junetalk.github.io/2014/06/13/hbase-code-about-htable-put/</link>
      <pubDate>Fri, 13 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/13/hbase-code-about-htable-put/</guid>
      <description>HBase版本：0.94.15-cdh4.7.0 在 HBase中，大部分的操作都是在RegionServer完成的，Client端想要插入、删</description>
    </item>
    
    <item>
      <title>HBase实现简单聚合计算</title>
      <link>https://junetalk.github.io/2014/06/12/hbase-aggregate-client/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/12/hbase-aggregate-client/</guid>
      <description>本文主要记录如何通过打补丁的方式将“hbase中实现简单聚合计算”的特性引入hbase源代码中，并介绍通过命令行和java代码的使用方法。 支</description>
    </item>
    
    <item>
      <title>HBase客户端实现并行扫描</title>
      <link>https://junetalk.github.io/2014/06/12/hbase-parallel-client-scanner/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/12/hbase-parallel-client-scanner/</guid>
      <description>HBase中有一个类可以实现客户端扫描数据，叫做ClientScanner，该类不是并行的，有没有办法实现一个并行的扫描类，加快扫描速度呢？</description>
    </item>
    
    <item>
      <title>Hive Over HBase的介绍</title>
      <link>https://junetalk.github.io/2014/06/12/intro-of-hive-over-hbase/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/12/intro-of-hive-over-hbase/</guid>
      <description>Hive Over HBase是基于Hive的HQL查询引擎支持对hbase表提供及时查询的功能，它并不是将hql语句翻译成mapreduce来运行，其响应</description>
    </item>
    
    <item>
      <title>Hive中数据的加载和导出</title>
      <link>https://junetalk.github.io/2014/06/09/hive-data-manipulation-language/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/09/hive-data-manipulation-language/</guid>
      <description>关于 Hive DML 语法，你可以参考 apache 官方文档的说明:Hive Data Manipulation Language。 apache的hive版本现在应该是 0.13.0，而我使用的 hadoop 版本是</description>
    </item>
    
    <item>
      <title>Hive中的FetchTask任务</title>
      <link>https://junetalk.github.io/2014/06/09/fetchtask-in-hive/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/09/fetchtask-in-hive/</guid>
      <description>Hive中有各种各样的Task任务，其中FetchTask算是最简单的一种了。FetchTask不同于MapReduce任务，它不会启动ma</description>
    </item>
    
    <item>
      <title>不用Cloudera Manager安装Cloudera Search</title>
      <link>https://junetalk.github.io/2014/06/03/install_cloudera_search_without_cm/</link>
      <pubDate>Tue, 03 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/06/03/install_cloudera_search_without_cm/</guid>
      <description>Cloudera Search 用来在 hadoop 基础上建立索引和全文检索，本文主要记录如何安装 CLoudera Search 的过程，其中也包括如何安装和启动 Zookeeper、Solr、MapReduc</description>
    </item>
    
    <item>
      <title>重装Mac系统之后</title>
      <link>https://junetalk.github.io/2014/04/23/after-reinstall-mac/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/04/23/after-reinstall-mac/</guid>
      <description>本文主要记录重装Mac系统之后的一些软件安装和环境变量配置。 系统偏好设置 触控板 系统设置 &amp;gt; 辅助功能 &amp;gt; 指针控制 &amp;gt; 触控板选项 &amp;gt; 启用拖移 &amp;gt; 三指拖移 系</description>
    </item>
    
    <item>
      <title>使用Lua和OpenResty搭建验证码服务器</title>
      <link>https://junetalk.github.io/2014/04/01/deploy-a-captcha-server-using-lua-and-openresty/</link>
      <pubDate>Tue, 01 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/04/01/deploy-a-captcha-server-using-lua-and-openresty/</guid>
      <description>Lua下有个Lua-GD图形库，通过简单的Lua语句就能控制、生成图片。 环境说明： 操作系统：RHEL6.4 RHEL系统默认已安装RPM包的L</description>
    </item>
    
    <item>
      <title>HBase笔记：Region拆分策略</title>
      <link>https://junetalk.github.io/2014/01/16/hbase-region-split-policy/</link>
      <pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/01/16/hbase-region-split-policy/</guid>
      <description>Region 概念 Region是表获取和分布的基本元素，由每个列族的一个Store组成。对象层级图如下： 1 2 3 4 5 6 Table (HBase table) Region (Regions for the table) Store (Store per ColumnFamily for each Region for the table)</description>
    </item>
    
    <item>
      <title>Hive使用HAProxy配置HA</title>
      <link>https://junetalk.github.io/2014/01/08/hive-ha-by-haproxy/</link>
      <pubDate>Wed, 08 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2014/01/08/hive-ha-by-haproxy/</guid>
      <description>HAProxy是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，HAProxy是完全免费的、借助HAP</description>
    </item>
    
    <item>
      <title>HiveServer2中使用jdbc客户端用户运行mapreduce</title>
      <link>https://junetalk.github.io/2013/10/17/run-mapreduce-with-client-user-in-hive-server2/</link>
      <pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/10/17/run-mapreduce-with-client-user-in-hive-server2/</guid>
      <description>最近做了个web系统访问hive数据库，类似于官方自带的hwi、安居客的hwi改进版和大众点评的polestar(github地址)系统，但</description>
    </item>
    
    <item>
      <title>安装RHadoop</title>
      <link>https://junetalk.github.io/2013/07/20/install-rhadoop/</link>
      <pubDate>Sat, 20 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/07/20/install-rhadoop/</guid>
      <description>1. R Language Install 安装相关依赖 1 2 3 4 yum install -y perl* pcre-devel tcl-devel zlib-devel bzip2-devel libX11-devel tk-devel tetex-latex *gfortran* compat-readline5 yum install libRmath-* rpm -Uvh --force --nodeps R-core-2.10.0-2.el5.x86_64.rpm rpm -Uvh R-2.10.0-2.el5.x86_64.rpm R-devel-2.10.0-2.el5.x86_64.rpm 编译安装：R-3.0.1 1 2 3 4 5 tar -zxvf R-3.0.1 ./configure make make install #R运行 export HADOOP_CMD=/usr/bin/hadoop 排</description>
    </item>
    
    <item>
      <title>HBase笔记：存储结构</title>
      <link>https://junetalk.github.io/2013/06/15/hbase-note-about-data-structure/</link>
      <pubDate>Sat, 15 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/06/15/hbase-note-about-data-structure/</guid>
      <description>从HBase的架构图上可以看出，HBase中的存储包括HMaster、HRegionServer、HRegion、Store、MemStor</description>
    </item>
    
    <item>
      <title>使用yum源安装CDH集群</title>
      <link>https://junetalk.github.io/2013/04/06/install-cloudera-cdh-by-yum/</link>
      <pubDate>Sat, 06 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/04/06/install-cloudera-cdh-by-yum/</guid>
      <description>本文主要是记录使用yum安装CDH Hadoop集群的过程，包括HDFS、Yarn、Hive和HBase。目前使用的是CDH6.2.0安装集群</description>
    </item>
    
    <item>
      <title>使用yum源安装Impala过程</title>
      <link>https://junetalk.github.io/2013/03/29/install-impala/</link>
      <pubDate>Fri, 29 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/03/29/install-impala/</guid>
      <description>与Hive类似，Impala也可以直接与HDFS和HBase库直接交互。只不过Hive和其它建立在MapReduce上的框架适合需要长时间运</description>
    </item>
    
    <item>
      <title>手动安装Cloudera HBase CDH</title>
      <link>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-hbase-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-hbase-CDH/</guid>
      <description>本文主要记录手动安装Cloudera HBase集群过程，环境设置及Hadoop安装过程见手动安装Cloudera Hadoop CDH,参考这篇文章，ha</description>
    </item>
    
    <item>
      <title>手动安装Cloudera Hive CDH</title>
      <link>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-hive-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-hive-CDH/</guid>
      <description>本文主要记录手动安装Cloudera Hive集群过程，环境设置及Hadoop安装过程见手动安装Cloudera Hadoop CDH,参考这篇文章，had</description>
    </item>
    
    <item>
      <title>手动安装Hadoop集群</title>
      <link>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-Hadoop-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://junetalk.github.io/2013/03/24/manual-install-Cloudera-Hadoop-CDH/</guid>
      <description>安装版本 centos版本为6。 hadoop各个组件和jdk版本如下： 1 2 3 4 hadoop-2.0.0-cdh4.6.0 hbase-0.94.15-cdh4.6.0 hive-0.10.0-cdh4.6.0 jdk1.6.0_38 hadoop各组件可以在这里下载。 安装前说明 确定安装目录</description>
    </item>
    
  </channel>
</rss>