<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hive on JavaChen Blog - Ramblings of a coder</title>
    <link>http://javachen.github.io/categories/hive/</link>
    <description>Recent content in hive on JavaChen Blog - Ramblings of a coder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 30 Apr 2015 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://javachen.github.io/categories/hive/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>安装和配置Sentry</title>
      <link>http://javachen.github.io/2015/04/30/install-and-config-sentry/</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2015/04/30/install-and-config-sentry/</guid>
      <description>本文主要记录安装和配置Sentry的过程，关于Sentry的介绍，请参考Apache Sentry架构介绍。 1. 环境说明 系统环境： 操作系统：Ce</description>
    </item>
    
    <item>
      <title>测试Hive集成Sentry</title>
      <link>http://javachen.github.io/2015/04/30/test-hive-with-sentry/</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2015/04/30/test-hive-with-sentry/</guid>
      <description>本文在安装和配置Sentry基础之上测试Hive集成Sentry。注意：这里Hive中并没有配置Kerberos认证。 关于配置了Kerber</description>
    </item>
    
    <item>
      <title>Apache Sentry架构介绍</title>
      <link>http://javachen.github.io/2015/04/29/apache-sentry-architecture/</link>
      <pubDate>Wed, 29 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2015/04/29/apache-sentry-architecture/</guid>
      <description>介绍 Apache Sentry是Cloudera公司发布的一个Hadoop开源组件，截止目前还是Apache的孵化项目，它提供了细粒度级、基于角色的授权</description>
    </item>
    
    <item>
      <title>配置安全的Hive集群集成Sentry</title>
      <link>http://javachen.github.io/2014/11/14/config-secured-hive-with-sentry/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/11/14/config-secured-hive-with-sentry/</guid>
      <description>本文主要记录配置安全的Hive集群集成Sentry的过程。Hive上配置了Kerberos认证，配置的过程请参考： 使用yum安装CDH Had</description>
    </item>
    
    <item>
      <title>Hive配置Kerberos认证</title>
      <link>http://javachen.github.io/2014/11/06/config-kerberos-in-cdh-hive/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/11/06/config-kerberos-in-cdh-hive/</guid>
      <description>1. 环境说明 系统环境： 操作系统：CentOs 6.6 Hadoop版本：CDH5.4 JDK版本：1.7.0_71 运行用户：root 集群各节点角色规划为</description>
    </item>
    
    <item>
      <title>当前数据仓库建设过程</title>
      <link>http://javachen.github.io/2014/10/23/hive-warehouse-in-2014/</link>
      <pubDate>Thu, 23 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/10/23/hive-warehouse-in-2014/</guid>
      <description>一个典型的企业数据仓库通常包含数据采集、数据加工和存储、数据展现等几个过程，本篇文章将按照这个顺序记录部门当前建设数据仓库的过程。 1. 数据采集</description>
    </item>
    
    <item>
      <title>Sqoop导入关系数据库到Hive</title>
      <link>http://javachen.github.io/2014/08/04/import-data-to-hive-with-sqoop/</link>
      <pubDate>Mon, 04 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/08/04/import-data-to-hive-with-sqoop/</guid>
      <description>Sqoop 是 apache 下用于 RDBMS 和 HDFS 互相导数据的工具。本文以 mysql 数据库为例，实现关系数据库导入到 hdfs 和 hive。 1. 安装 Sqoop 使用 rpm 安装即可。 1 yum install sqoop sqoop-metastore -y 安装完之后需要</description>
    </item>
    
    <item>
      <title>采集日志到Hive</title>
      <link>http://javachen.github.io/2014/07/25/collect-log-to-hive/</link>
      <pubDate>Fri, 25 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/07/25/collect-log-to-hive/</guid>
      <description>我们现在的需求是需要将线上的日志以小时为单位采集并存储到 hive 数据库中，方便以后使用 mapreduce 或者 impala 做数据分析。为了实现这个目标调研了 flume 如何采集数据到 h</description>
    </item>
    
    <item>
      <title>Hive中的排序语法</title>
      <link>http://javachen.github.io/2014/06/22/sort-in-hive-query/</link>
      <pubDate>Sun, 22 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/06/22/sort-in-hive-query/</guid>
      <description>ORDER BY hive中的ORDER BY语句和关系数据库中的sql语法相似。他会对查询结果做全局排序，这意味着所有的数据会传送到一个Reduce任务上</description>
    </item>
    
    <item>
      <title>Hive Over HBase的介绍</title>
      <link>http://javachen.github.io/2014/06/12/intro-of-hive-over-hbase/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/06/12/intro-of-hive-over-hbase/</guid>
      <description>Hive Over HBase是基于Hive的HQL查询引擎支持对hbase表提供及时查询的功能，它并不是将hql语句翻译成mapreduce来运行，其响应</description>
    </item>
    
    <item>
      <title>Hive中数据的加载和导出</title>
      <link>http://javachen.github.io/2014/06/09/hive-data-manipulation-language/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/06/09/hive-data-manipulation-language/</guid>
      <description>关于 Hive DML 语法，你可以参考 apache 官方文档的说明:Hive Data Manipulation Language。 apache的hive版本现在应该是 0.13.0，而我使用的 hadoop 版本是</description>
    </item>
    
    <item>
      <title>Hive中的FetchTask任务</title>
      <link>http://javachen.github.io/2014/06/09/fetchtask-in-hive/</link>
      <pubDate>Mon, 09 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/06/09/fetchtask-in-hive/</guid>
      <description>Hive中有各种各样的Task任务，其中FetchTask算是最简单的一种了。FetchTask不同于MapReduce任务，它不会启动ma</description>
    </item>
    
    <item>
      <title>Hive使用HAProxy配置HA</title>
      <link>http://javachen.github.io/2014/01/08/hive-ha-by-haproxy/</link>
      <pubDate>Wed, 08 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2014/01/08/hive-ha-by-haproxy/</guid>
      <description>HAProxy是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，HAProxy是完全免费的、借助HAP</description>
    </item>
    
    <item>
      <title>手动安装Cloudera Hive CDH</title>
      <link>http://javachen.github.io/2013/03/24/manual-install-Cloudera-hive-CDH/</link>
      <pubDate>Sun, 24 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>http://javachen.github.io/2013/03/24/manual-install-Cloudera-hive-CDH/</guid>
      <description>本文主要记录手动安装Cloudera Hive集群过程，环境设置及Hadoop安装过程见手动安装Cloudera Hadoop CDH,参考这篇文章，had</description>
    </item>
    
  </channel>
</rss>