<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Hive中如何确定map数 - JavaChen Blog - Ramblings of a coder</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="JavaChen" /><meta name="description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？" /><meta name="keywords" content="Java, Hadoop, Docker" />


<meta name="baidu-site-verification" content="OMsbiDfo1G" />



<meta name="generator" content="Hugo 0.58.3 with theme even" />


<link rel="canonical" href="http://localhost:1313/2013/09/04/how-to-decide-map-number/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">
<link rel="stylesheet" href="/css/custom.css">


<meta property="og:title" content="Hive中如何确定map数" />
<meta property="og:description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/2013/09/04/how-to-decide-map-number/" />
<meta property="article:published_time" content="2013-09-04T00:00:00+08:00" />
<meta property="article:modified_time" content="2013-09-04T00:00:00+08:00" />
<meta itemprop="name" content="Hive中如何确定map数">
<meta itemprop="description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？">


<meta itemprop="datePublished" content="2013-09-04T00:00:00&#43;08:00" />
<meta itemprop="dateModified" content="2013-09-04T00:00:00&#43;08:00" />
<meta itemprop="wordCount" content="4027">



<meta itemprop="keywords" content="hive,mapreduce," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Hive中如何确定map数"/>
<meta name="twitter:description" content="Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">JavaChen Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">JavaChen Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Hive中如何确定map数</h1>

      <div class="post-meta">
        <span class="post-time"> 2013-09-04 </span>
        
          <span class="more-meta"> 约 4027 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#hive-默认的-input-format">hive 默认的 input format</a></li>
<li><a href="#inputformat-接口功能">InputFormat 接口功能</a></li>
<li><a href="#hiveinputformat">HiveInputFormat</a></li>
<li><a href="#combinehiveinputformat">CombineHiveInputFormat</a></li>
<li><a href="#hive-中如何确定-map-数">hive 中如何确定 map 数</a></li>
<li><a href="#总结">总结</a>
<ul>
<li><a href="#1-map-数不是越多越好">1. map 数不是越多越好</a></li>
<li><a href="#2-如何适当的增加-map-数">2. 如何适当的增加 map 数？</a></li>
<li><a href="#3-一些经验">3. 一些经验</a></li>
</ul></li>
<li><a href="#参考文章">参考文章</a></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<p>Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？</p>

<p>本文测试集群版本：<code>cdh-4.3.0</code> 。</p>

<h1 id="hive-默认的-input-format">hive 默认的 input format</h1>

<p>在 <code>cdh-4.3.0</code> 的 hive 中查看 <code>hive.input.format</code> 值（为什么是<code>hive.input.format</code>？）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">hive&gt; <span class="nb">set</span> hive.input.format<span class="p">;</span>
hive.input.format<span class="o">=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat<span class="p">;</span></code></pre></td></tr></table>
</div>
</div>
<p>可以看到默认值为 CombineHiveInputFormat，如果你使用的是 <code>IDH</code> 的hive，则默认值为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">hive&gt; <span class="nb">set</span> hive.input.format<span class="p">;</span>
hive.input.format<span class="o">=</span>org.apache.hadoop.hive.ql.io.HiveInputFormat<span class="p">;</span></code></pre></td></tr></table>
</div>
</div>
<p>CombineHiveInputFormat 类继承自 HiveInputFormat，而 HiveInputFormat 实现了 <code>org.apache.hadoop.mapred.InputFormat</code> 接口，关于 InputFormat 的分析，可以参考<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a>.</p>

<h1 id="inputformat-接口功能">InputFormat 接口功能</h1>

<p>简单来说，InputFormat 主要用于描述输入数据的格式，提供了以下两个功能：</p>

<p>1)、数据切分，按照某个策略将输入数据且分成若干个 split，以便确定 Map Task 的个数即 Mapper 的个数，在 MapReduce 框架中，一个 split 就意味着需要一个 Map Task;</p>

<p>2)、为 Mapper 提供输入数据，即给定一个 split(使用其中的 RecordReader 对象)将之解析为一个个的 key/value 键值对。</p>

<p>该类接口定义如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="nf">interface</span> <span class="n">InputFormat</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="o">&gt;</span><span class="p">{</span>
	<span class="kd">public</span> <span class="nf">InputSplit</span><span class="p">[]</span> <span class="n">getSplits</span><span class="p">(</span><span class="n">JobConf</span> <span class="nf">job</span><span class="p">,</span><span class="kt">int</span> <span class="nf">numSplits</span><span class="p">)</span> <span class="kd">throws</span> <span class="nf">IOException</span><span class="p">;</span> 
	<span class="kd">public</span> <span class="nf">RecordReader</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="o">&gt;</span> <span class="nf">getRecordReader</span><span class="p">(</span><span class="n">InputSplit</span> <span class="nf">split</span><span class="p">,</span><span class="n">JobConf</span> <span class="nf">job</span><span class="p">,</span><span class="n">Reporter</span> <span class="nf">reporter</span><span class="p">)</span> <span class="kd">throws</span> <span class="nf">IOException</span><span class="p">;</span> 
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>其中，<code>getSplit()</code> 方法主要用于切分数据，每一份数据由，split 只是在逻辑上对数据分片，并不会在磁盘上将数据切分成 split 物理分片，实际上数据在 HDFS 上还是以 block 为基本单位来存储数据的。InputSplit 只记录了 Mapper 要处理的数据的元数据信息，如起始位置、长度和所在的节点。</p>

<p>MapReduce 自带了一些 InputFormat 的实现类：</p>

<p><img src="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg" alt="InputFormat实现类" /></p>

<p>hive 中有一些 InputFormat 的实现类，如：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="n">AvroContainerInputFormat</span>
<span class="nf">RCFileBlockMergeInputFormat</span>
<span class="n">RCFileInputFormat</span>
<span class="nf">FlatFileInputFormat</span>
<span class="n">OneNullRowInputFormat</span>
<span class="nf">ReworkMapredInputFormat</span>
<span class="n">SymbolicInputFormat</span>
<span class="nf">SymlinkTextInputFormat</span>
<span class="n">HiveInputFormat</span></code></pre></td></tr></table>
</div>
</div>
<p>HiveInputFormat 的子类有：</p>

<p><img src="/images/implement-of-hiveinputformat.png" alt="HiveInputFormat的子类" /></p>

<h1 id="hiveinputformat">HiveInputFormat</h1>

<p>以 HiveInputFormat 为例，看看其getSplit()方法逻辑：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="k">for</span> <span class="p">(</span><span class="n">Path</span> <span class="nf">dir</span> <span class="o">:</span> <span class="n">dirs</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">PartitionDesc</span> <span class="nf">part</span> <span class="o">=</span> <span class="n">getPartitionDescFromPath</span><span class="p">(</span><span class="n">pathToPartitionInfo</span><span class="p">,</span> <span class="n">dir</span><span class="p">);</span>
  <span class="c1">// create a new InputFormat instance if this is the first time to see this
</span><span class="c1"></span>  <span class="c1">// class
</span><span class="c1"></span>  <span class="n">Class</span> <span class="nf">inputFormatClass</span> <span class="o">=</span> <span class="n">part</span><span class="p">.</span><span class="na">getInputFileFormatClass</span><span class="p">();</span>
  <span class="n">InputFormat</span> <span class="nf">inputFormat</span> <span class="o">=</span> <span class="n">getInputFormatFromCache</span><span class="p">(</span><span class="n">inputFormatClass</span><span class="p">,</span> <span class="n">job</span><span class="p">);</span>
  <span class="n">Utilities</span><span class="p">.</span><span class="na">copyTableJobPropertiesToConf</span><span class="p">(</span><span class="n">part</span><span class="p">.</span><span class="na">getTableDesc</span><span class="p">(),</span> <span class="n">newjob</span><span class="p">);</span>

  <span class="c1">// Make filter pushdown information available to getSplits.
</span><span class="c1"></span>  <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="nf">aliases</span> <span class="o">=</span>
      <span class="n">mrwork</span><span class="p">.</span><span class="na">getPathToAliases</span><span class="p">().</span><span class="na">get</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="na">toUri</span><span class="p">().</span><span class="na">toString</span><span class="p">());</span>
  <span class="k">if</span> <span class="p">((</span><span class="n">aliases</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">aliases</span><span class="p">.</span><span class="na">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">1</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">Operator</span> <span class="nf">op</span> <span class="o">=</span> <span class="n">mrwork</span><span class="p">.</span><span class="na">getAliasToWork</span><span class="p">().</span><span class="na">get</span><span class="p">(</span><span class="n">aliases</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="n">0</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">op</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">op</span> <span class="nf">instanceof</span> <span class="n">TableScanOperator</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">TableScanOperator</span> <span class="nf">tableScan</span> <span class="o">=</span> <span class="p">(</span><span class="n">TableScanOperator</span><span class="p">)</span> <span class="n">op</span><span class="p">;</span>
      <span class="n">pushFilters</span><span class="p">(</span><span class="n">newjob</span><span class="p">,</span> <span class="n">tableScan</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">FileInputFormat</span><span class="p">.</span><span class="na">setInputPaths</span><span class="p">(</span><span class="n">newjob</span><span class="p">,</span> <span class="n">dir</span><span class="p">);</span>
  <span class="n">newjob</span><span class="p">.</span><span class="na">setInputFormat</span><span class="p">(</span><span class="n">inputFormat</span><span class="p">.</span><span class="na">getClass</span><span class="p">());</span>
  <span class="n">InputSplit</span><span class="p">[]</span> <span class="nf">iss</span> <span class="o">=</span> <span class="n">inputFormat</span><span class="p">.</span><span class="na">getSplits</span><span class="p">(</span><span class="n">newjob</span><span class="p">,</span> <span class="n">numSplits</span> <span class="o">/</span> <span class="n">dirs</span><span class="p">.</span><span class="na">length</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">InputSplit</span> <span class="nf">is</span> <span class="o">:</span> <span class="n">iss</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">result</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="k">new</span> <span class="n">HiveInputSplit</span><span class="p">(</span><span class="n">is</span><span class="p">,</span> <span class="n">inputFormatClass</span><span class="p">.</span><span class="na">getName</span><span class="p">()));</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>上面代码主要过程是：</p>

<blockquote>
<p>遍历每个输入目录，然后获得 PartitionDesc 对象，从该对象调用 getInputFileFormatClass 方法得到实际的 InputFormat 类，并调用其 <code>getSplits(newjob, numSplits / dirs.length)</code> 方法。</p>
</blockquote>

<p>按照上面代码逻辑，似乎 hive 中每一个表都应该有一个 InputFormat 实现类。在 hive 中运行下面代码，可以查看建表语句：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-sql" data-lang="sql"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sql" data-lang="sql"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">show</span> <span class="k">create</span> <span class="k">table</span> <span class="n">info</span><span class="p">;</span> 
<span class="n">OK</span>
<span class="k">CREATE</span>  <span class="k">TABLE</span> <span class="n">info</span><span class="p">(</span>
  <span class="n">statist_date</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">statistics_date</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">inner_code</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">office_no</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">window_no</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">ticket_no</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">id_kind</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">id_no</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">id_name</span> <span class="n">string</span><span class="p">,</span> 
  <span class="n">area_center_code</span> <span class="n">string</span><span class="p">)</span>
<span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> 
  <span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\;&#39;</span> 
  <span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\n&#39;</span> 
<span class="n">STORED</span> <span class="k">AS</span> <span class="n">INPUTFORMAT</span> 
  <span class="s1">&#39;org.apache.hadoop.mapred.TextInputFormat&#39;</span> 
<span class="n">OUTPUTFORMAT</span> 
  <span class="s1">&#39;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#39;</span>
<span class="k">LOCATION</span>
  <span class="s1">&#39;hdfs://node:8020/user/hive/warehouse/info&#39;</span>
<span class="n">TBLPROPERTIES</span> <span class="p">(</span>
  <span class="s1">&#39;numPartitions&#39;</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> 
  <span class="s1">&#39;numFiles&#39;</span><span class="o">=</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> 
  <span class="s1">&#39;transient_lastDdlTime&#39;</span><span class="o">=</span><span class="s1">&#39;1378245263&#39;</span><span class="p">,</span> 
  <span class="s1">&#39;numRows&#39;</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> 
  <span class="s1">&#39;totalSize&#39;</span><span class="o">=</span><span class="s1">&#39;301240320&#39;</span><span class="p">,</span> 
  <span class="s1">&#39;rawDataSize&#39;</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">)</span>
<span class="n">Time</span> <span class="n">taken</span><span class="p">:</span> <span class="mi">0</span><span class="p">.</span><span class="mi">497</span> <span class="n">seconds</span></code></pre></td></tr></table>
</div>
</div>
<p>从上面可以看到 info 表的 INPUTFORMAT 为<code>org.apache.hadoop.mapred.TextInputFormat</code>，TextInputFormat 继承自FileInputFormat。FileInputFormat 是一个抽象类，它最重要的功能是为各种 InputFormat 提供统一的 <code>getSplits()</code>方法，该方法最核心的是文件切分算法和 Host 选择算法。</p>

<p>算法如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kt">long</span> <span class="nf">length</span> <span class="o">=</span> <span class="n">file</span><span class="p">.</span><span class="na">getLen</span><span class="p">();</span>
<span class="kt">long</span> <span class="nf">goalSize</span> <span class="o">=</span> <span class="n">totalSize</span> <span class="o">/</span> <span class="p">(</span><span class="n">numSplits</span> <span class="o">==</span> <span class="n">0</span> <span class="o">?</span> <span class="n">1</span> <span class="o">:</span> <span class="n">numSplits</span><span class="p">);</span>
<span class="kt">long</span> <span class="nf">minSize</span> <span class="o">=</span> <span class="n">Math</span><span class="p">.</span><span class="na">max</span><span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="na">getLong</span><span class="p">(</span><span class="n">org</span><span class="p">.</span><span class="na">apache</span><span class="p">.</span><span class="na">hadoop</span><span class="p">.</span><span class="na">mapreduce</span><span class="p">.</span><span class="na">lib</span><span class="p">.</span><span class="na">input</span><span class="p">.</span>
<span class="nf">FileInputFormat</span><span class="p">.</span><span class="na">SPLIT_MINSIZE</span><span class="p">,</span> <span class="n">1</span><span class="p">),</span> <span class="n">minSplitSize</span><span class="p">);</span>

<span class="kt">long</span> <span class="nf">blockSize</span> <span class="o">=</span> <span class="n">file</span><span class="p">.</span><span class="na">getBlockSize</span><span class="p">();</span>
<span class="kt">long</span> <span class="nf">splitSize</span> <span class="o">=</span> <span class="n">computeSplitSize</span><span class="p">(</span><span class="n">goalSize</span><span class="p">,</span> <span class="n">minSize</span><span class="p">,</span> <span class="n">blockSize</span><span class="p">);</span>
<span class="kt">long</span> <span class="nf">bytesRemaining</span> <span class="o">=</span> <span class="n">length</span><span class="p">;</span>
<span class="k">while</span> <span class="p">(((</span><span class="kt">double</span><span class="p">)</span> <span class="n">bytesRemaining</span><span class="p">)</span><span class="o">/</span><span class="n">splitSize</span> <span class="o">&gt;</span> <span class="n">SPLIT_SLOP</span><span class="p">)</span> <span class="p">{</span>
<span class="n">String</span><span class="p">[]</span> <span class="nf">splitHosts</span> <span class="o">=</span> <span class="n">getSplitHosts</span><span class="p">(</span><span class="n">blkLocations</span><span class="p">,</span> 
	<span class="n">length</span><span class="o">-</span><span class="n">bytesRemaining</span><span class="p">,</span> <span class="n">splitSize</span><span class="p">,</span> <span class="n">clusterMap</span><span class="p">);</span>
	<span class="n">splits</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">makeSplit</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">length</span><span class="o">-</span><span class="n">bytesRemaining</span><span class="p">,</span> <span class="n">splitSize</span><span class="p">,</span> 
		       <span class="n">splitHosts</span><span class="p">));</span>
	<span class="n">bytesRemaining</span> <span class="o">-=</span> <span class="n">splitSize</span><span class="p">;</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<hr />

<p><code>华丽的分割线</code>：以下摘抄自<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></p>

<p><strong>1）文件切分算法</strong></p>

<p>文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段，FileInputSplit以文件为单位切分生成InputSplit。有三个属性值来确定InputSplit的个数：</p>

<ul>
<li><code>goalSize</code>：该值由 <code>totalSize/numSplits</code> 来确定 InputSplit 的长度，它是根据用户的期望的 InputSplit 个数计算出来的；numSplits 为用户设定的 Map Task 的个数，默认为1。</li>
<li><code>minSize</code>：由配置参数 <code>mapred.min.split.size</code>（或者 <code>mapreduce.input.fileinputformat.split.minsize</code>）决定的 InputForma t的最小长度，默认为1。</li>
<li><code>blockSize</code>：HDFS 中的文件存储块block的大小，默认为64MB。</li>
<li><code>numSplits=mapred.map.tasks</code> 或者 <code>mapreduce.job.maps</code></li>
</ul>

<p>这三个参数决定一个 InputFormat 分片的最终的长度，计算方法如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="n">splitSize</span> <span class="o">=</span> <span class="n">max</span><span class="p">{</span><span class="n">minSize</span><span class="p">,</span><span class="n">min</span><span class="p">{</span><span class="n">goalSize</span><span class="p">,</span><span class="n">blockSize</span><span class="p">}}</span> </code></pre></td></tr></table>
</div>
</div>
<p>计算出了分片的长度后，也就确定了 InputFormat 的数目。</p>

<p><strong>2）host 选择算法</strong></p>

<p>InputFormat 的切分方案确定后，接下来就是要确定每一个 InputSplit 的元数据信息。InputSplit 元数据通常包括四部分，<code>&lt;file,start,length,hosts&gt;</code>其意义为：</p>

<ul>
<li>file 标识 InputSplit 分片所在的文件；</li>
<li>InputSplit 分片在文件中的的起始位置；</li>
<li>InputSplit 分片的长度；</li>
<li>分片所在的 host 节点的列表。</li>
</ul>

<p>InputSplit 的 host 列表的算作策略直接影响到运行作业的本地性。</p>

<p>我们知道，由于大文件存储在 HDFS上的 block 可能会遍布整个 Hadoop 集群，而一个 InputSplit 分片的划分算法可能会导致一个 split 分片对应多个不在同一个节点上的 blocks，这就会使得在 Map Task 执行过程中会涉及到读其他节点上的属于该 Task 的 block 中的数据，从而不能实现数据本地性，而造成更多的网络传输开销。</p>

<p>一个 InputSplit 分片对应的 blocks 可能位于多个数据节点地上，但是基于任务调度的效率，通常情况下，不会把一个分片涉及的所有的节点信息都加到其host列表中，而是选择包含该分片的数据总量的最大的前几个节点，作为任务调度时判断是否具有本地性的主要凭证。</p>

<p>FileInputFormat 使用了一个启发式的 host 选择算法：首先按照 rack 机架包含的数据量对 rack 排序，然后再在 rack 内部按照每个 node 节点包含的数据量对 node 排序，最后选取前 N 个(N 为 block 的副本数)，node 的 host 作为 InputSplit 分片的 host 列表。当任务地调度 Task 作业时，只要将 Task 调度给 host 列表上的节点，就可以认为该 Task 满足了本地性。</p>

<p>从上面的信息我们可以知道，当 InputSplit 分片的大小大于 block 的大小时，Map Task 并不能完全满足数据的本地性，总有一本分的数据要通过网络从远程节点上读数据，故为了提高 Map Task 的数据本地性，减少网络传输的开销，应尽量是 InputFormat 的大小和 HDFS 的 block 块大小相同。</p>

<hr />

<h1 id="combinehiveinputformat">CombineHiveInputFormat</h1>

<p><code>getSplits(JobConf job, int numSplits)</code> 代码运行过程如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="n">init</span><span class="p">(</span><span class="n">job</span><span class="p">);</span>
<span class="n">CombineFileInputFormatShim</span> <span class="nf">combine</span> <span class="o">=</span> <span class="n">ShimLoader</span><span class="p">.</span><span class="na">getHadoopShims</span><span class="p">().</span><span class="na">getCombineFileInputFormat</span><span class="p">();</span>
	<span class="n">ShimLoader</span><span class="p">.</span><span class="na">loadShims</span><span class="p">(</span><span class="n">HADOOP_SHIM_CLASSES</span><span class="p">,</span> <span class="n">HadoopShims</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
		<span class="n">Hadoop23Shims</span>
			<span class="nf">HadoopShimsSecure</span><span class="p">.</span><span class="na">getCombineFileInputFormat</span><span class="p">()</span></code></pre></td></tr></table>
</div>
</div>
<p>CombineFileInputFormatShim 继承了<code>org.apache.hadoop.mapred.lib.CombineFileInputFormat</code>，CombineFileInputFormatShim 的 <code>getSplits</code> 方法代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="nf">InputSplitShim</span><span class="p">[]</span> <span class="n">getSplits</span><span class="p">(</span><span class="n">JobConf</span> <span class="nf">job</span><span class="p">,</span> <span class="kt">int</span> <span class="nf">numSplits</span><span class="p">)</span> <span class="kd">throws</span> <span class="nf">IOException</span> <span class="p">{</span>
  <span class="kt">long</span> <span class="nf">minSize</span> <span class="o">=</span> <span class="n">job</span><span class="p">.</span><span class="na">getLong</span><span class="p">(</span><span class="s">&#34;mapred.min.split.size&#34;</span><span class="p">,</span> <span class="n">0</span><span class="p">);</span>

  <span class="c1">// For backward compatibility, let the above parameter be used
</span><span class="c1"></span>  <span class="k">if</span> <span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="na">getLong</span><span class="p">(</span><span class="s">&#34;mapred.min.split.size.per.node&#34;</span><span class="p">,</span> <span class="n">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">super</span><span class="p">.</span><span class="na">setMinSplitSizeNode</span><span class="p">(</span><span class="n">minSize</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="na">getLong</span><span class="p">(</span><span class="s">&#34;mapred.min.split.size.per.rack&#34;</span><span class="p">,</span> <span class="n">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">super</span><span class="p">.</span><span class="na">setMinSplitSizeRack</span><span class="p">(</span><span class="n">minSize</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="na">getLong</span><span class="p">(</span><span class="s">&#34;mapred.max.split.size&#34;</span><span class="p">,</span> <span class="n">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">super</span><span class="p">.</span><span class="na">setMaxSplitSize</span><span class="p">(</span><span class="n">minSize</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="n">InputSplit</span><span class="p">[]</span> <span class="nf">splits</span> <span class="o">=</span> <span class="p">(</span><span class="n">InputSplit</span><span class="p">[])</span> <span class="kd">super</span><span class="p">.</span><span class="na">getSplits</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">numSplits</span><span class="p">);</span>

  <span class="n">InputSplitShim</span><span class="p">[]</span> <span class="nf">isplits</span> <span class="o">=</span> <span class="k">new</span> <span class="n">InputSplitShim</span><span class="p">[</span><span class="n">splits</span><span class="p">.</span><span class="na">length</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="nf">pos</span> <span class="o">=</span> <span class="n">0</span><span class="p">;</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="n">splits</span><span class="p">.</span><span class="na">length</span><span class="p">;</span> <span class="n">pos</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">isplits</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="k">new</span> <span class="n">InputSplitShim</span><span class="p">((</span><span class="n">CombineFileSplit</span><span class="p">)</span><span class="n">splits</span><span class="p">[</span><span class="n">pos</span><span class="p">]);</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">isplits</span><span class="p">;</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>从上面代码可以看出，如果为 CombineHiveInputFormat，则以下四个参数起作用：</p>

<ul>
<li><code>mapred.min.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize</code>。</li>
<li><code>mapred.max.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.maxsize</code>。</li>
<li><code>mapred.min.split.size.per.rack</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.rack</code>。</li>
<li><code>mapred.min.split.size.per.node</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.node</code>。</li>
</ul>

<p>CombineFileInputFormatShim 的 getSplits 方法最终会调用父类的 getSplits 方法，拆分算法如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-java" data-lang="java"><span class="kt">long</span> <span class="nf">left</span> <span class="o">=</span> <span class="n">locations</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="na">getLength</span><span class="p">();</span>
<span class="kt">long</span> <span class="nf">myOffset</span> <span class="o">=</span> <span class="n">locations</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="na">getOffset</span><span class="p">();</span>
<span class="kt">long</span> <span class="nf">myLength</span> <span class="o">=</span> <span class="n">0</span><span class="p">;</span>
<span class="k">do</span> <span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">maxSize</span> <span class="o">==</span> <span class="n">0</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">myLength</span> <span class="o">=</span> <span class="n">left</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">left</span> <span class="o">&gt;</span> <span class="n">maxSize</span> <span class="o">&amp;&amp;</span> <span class="n">left</span> <span class="o">&lt;</span> <span class="n">2</span> <span class="o">*</span> <span class="n">maxSize</span><span class="p">)</span> <span class="p">{</span>
	  <span class="n">myLength</span> <span class="o">=</span> <span class="n">left</span> <span class="o">/</span> <span class="n">2</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
	  <span class="n">myLength</span> <span class="o">=</span> <span class="n">Math</span><span class="p">.</span><span class="na">min</span><span class="p">(</span><span class="n">maxSize</span><span class="p">,</span> <span class="n">left</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="p">}</span>
	<span class="n">OneBlockInfo</span> <span class="nf">oneblock</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OneBlockInfo</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">myOffset</span><span class="p">,</span>
	  <span class="n">myLength</span><span class="p">,</span> <span class="n">locations</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="na">getHosts</span><span class="p">(),</span> <span class="n">locations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
	      <span class="p">.</span><span class="na">getTopologyPaths</span><span class="p">());</span>
	<span class="n">left</span> <span class="o">-=</span> <span class="n">myLength</span><span class="p">;</span>
	<span class="n">myOffset</span> <span class="o">+=</span> <span class="n">myLength</span><span class="p">;</span>

	<span class="n">blocksList</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">oneblock</span><span class="p">);</span>
<span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="n">left</span> <span class="o">&gt;</span> <span class="n">0</span><span class="p">);</span></code></pre></td></tr></table>
</div>
</div>
<h1 id="hive-中如何确定-map-数">hive 中如何确定 map 数</h1>

<p>总上总结如下：</p>

<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat</code>，则这时候的参数如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">hive&gt; <span class="nb">set</span> mapred.min.split.size<span class="p">;</span>
mapred.min.split.size<span class="o">=</span><span class="m">1</span>
hive&gt; <span class="nb">set</span> mapred.map.tasks<span class="p">;</span>
mapred.map.tasks<span class="o">=</span><span class="m">2</span>
hive&gt; <span class="nb">set</span> dfs.blocksize<span class="p">;</span>
dfs.blocksize<span class="o">=</span><span class="m">134217728</span></code></pre></td></tr></table>
</div>
</div>
<p>上面参数中 <code>mapred.map.tasks</code> 为2，<code>dfs.blocksize</code>（使用的是 cdh-4.3.0 版本的 hadoop，这里 block 和 size 之间没有逗号）为128M。</p>

<p>假设有一个文件为200M，则按上面 <code>HiveInputFormat</code> 的 split 算法：</p>

<p>1、文件总大小为200M，goalSize=200M /2 =100M，minSize=1 ，splitSize = max{1,min{100M,128M}} =100M</p>

<p>2、200M / 100M &gt;1.1,故第一块大小为100M</p>

<p>3、剩下文件大小为100M，小于128M，故第二块大小为100M。</p>

<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</code>，则这时候的参数如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">hive&gt; <span class="nb">set</span> mapred.min.split.size<span class="p">;</span>
mapred.min.split.size<span class="o">=</span><span class="m">1</span>
hive&gt; <span class="nb">set</span> mapred.max.split.size<span class="p">;</span>
mapred.max.split.size<span class="o">=</span><span class="m">67108864</span>
hive&gt; <span class="nb">set</span> mapred.min.split.size.per.rack<span class="p">;</span>
mapred.min.split.size.per.rack<span class="o">=</span><span class="m">1</span>
hive&gt; <span class="nb">set</span> mapred.min.split.size.per.node<span class="p">;</span>
mapred.min.split.size.per.node<span class="o">=</span><span class="m">1</span>
hive&gt; <span class="nb">set</span> dfs.blocksize<span class="p">;</span>
dfs.blocksize<span class="o">=</span><span class="m">134217728</span></code></pre></td></tr></table>
</div>
</div>
<p>上面参数中 <code>mapred.max.split.size</code> 为64M，<code>dfs.blocksize</code> 为128M。</p>

<p>假设有一个文件为200M，则按上面 <code>CombineHiveInputFormat</code> 的 split 算法：</p>

<p>1、128M &lt; 200M &lt;128M X 2，故第一个block大小为128M</p>

<p>2、剩下文件大小为200M-128M=72M，72M &lt; 128M,故第二块大小为72M</p>

<h1 id="总结">总结</h1>

<p>网上有一些文章关于 hive 中如何控制 map 数的文章是否考虑的不够全面，没有具体情况具体分析。简而言之，当 InputFormat 的实现类为不同类时，拆分块算法都不一样，相关设置参数也不一样，需要具体分析。</p>

<h2 id="1-map-数不是越多越好">1. map 数不是越多越好</h2>

<p>如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个 map 任务来完成，而一个 map 任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。
而且，同时可执行的 map 数是受限的。</p>

<h2 id="2-如何适当的增加-map-数">2. 如何适当的增加 map 数？</h2>

<ul>
<li>将数据导入到 hive 前，手动将大文件拆分为小文件</li>
<li>指定 map 数，使用 <code>insert</code> 或者 <code>create as select</code> 语句将一个表导入到另一个表，然后对另一张表做查询</li>
</ul>

<h2 id="3-一些经验">3. 一些经验</h2>

<ul>
<li><p>合并小文件可以减少 map 数，但是会增加网络 IO。</p></li>

<li><p>尽量使拆分块大小和 hdfs 的块大小接近，避免一个拆分块大小上的多个 hdfs 块位于不同数据节点，从而降低网络 IO。</p></li>

<li><p>根据实际情况，控制 map 数量需要遵循两个原则：<code>使大数据量利用合适的map数</code>；<code>使单个map任务处理合适的数据量。</code></p></li>
</ul>

<h1 id="参考文章">参考文章</h1>

<ul>
<li>[1] <a href="http://f.dataguru.cn/thread-149820-1-1.html">hive的查询注意事项以及优化总结</a></li>
<li>[2] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c010178qd.html">Hadoop中map数的计算</a></li>
<li>[3] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c0101aqvv.html">[Hive]从一个经典案例看优化mapred.map.tasks的重要性</a></li>
<li>[4] <a href="http://superlxw1234.iteye.com/blog/1582880">hive优化之&mdash;&mdash;控制hive任务中的map数和reduce数</a></li>
<li>[5] <a href="http://www.searchtb.com/2010/12/hadoop-job-tuning.html">Hadoop Job Tuning</a></li>
<li>[6] <a href="http://www.tuicool.com/articles/77f2Af">Hive配置项的含义详解（2）</a></li>
<li>[7] <a href="http://blog.csdn.net/lalaguozhe/article/details/9053645">Hive小文件合并调研</a></li>
<li>[8] <a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">JavaChen</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2013-09-04
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/wechatpay.jpg">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="/images/alipay.jpg">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/hive/">hive</a>
          <a href="/tags/mapreduce/">mapreduce</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/2013/10/17/cartesian-product-in-hive-inner-join/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Hive连接产生笛卡尔集</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/2013/08/23/publish-proerties-using-zookeeper/">
            <span class="next-text nav-default">使用ZooKeeper实现配置同步</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="javachen/javachen.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:junecloud@163.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/javachen" class="iconfont icon-github" title="github"></a>
      <a href="http://weibo.com/chenzhijun" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://space.bilibili.com/287563020/" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2009 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">JavaChen</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>

<script id="baidu_analytics">
  var _hmt = _hmt || [];
  (function() {
    if (window.location.hostname === 'localhost') return;
    var hm = document.createElement("script"); hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?7eaf37274cf8796df56903a88389e82f";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>






</body>
</html>
